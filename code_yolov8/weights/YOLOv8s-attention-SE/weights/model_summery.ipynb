{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\14794\\\\yolov8\\\\code_yolov8\\\\weights\\\\YOLOv8s-attention-SE\\\\weights'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os,sys\n",
    "# os.chdir('../')\n",
    "# os.chdir('../')\n",
    "# os.chdir('../')\n",
    "# os.chdir('./ultralytics')\n",
    "# %cd 'C:/Users/14794/yolov8/code_yolov8'\n",
    "# os.getcwd()\n",
    "sys.path.append('C:\\\\Users\\\\14794\\\\yolov8\\\\code_yolov8\\\\ultralytics')\n",
    "sys.path[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch': -1,\n",
       " 'best_fitness': None,\n",
       " 'model': DetectionModel(\n",
       "   (model): Sequential(\n",
       "     (0): Conv(\n",
       "       (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "       (act): SiLU(inplace=True)\n",
       "     )\n",
       "     (1): Conv(\n",
       "       (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "       (act): SiLU(inplace=True)\n",
       "     )\n",
       "     (2): C2f(\n",
       "       (cv1): Conv(\n",
       "         (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (cv2): Conv(\n",
       "         (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (m): ModuleList(\n",
       "         (0): Bottleneck(\n",
       "           (cv1): Conv(\n",
       "             (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (cv2): Conv(\n",
       "             (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (3): Conv(\n",
       "       (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "       (act): SiLU(inplace=True)\n",
       "     )\n",
       "     (4): C2f(\n",
       "       (cv1): Conv(\n",
       "         (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (cv2): Conv(\n",
       "         (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (m): ModuleList(\n",
       "         (0-1): 2 x Bottleneck(\n",
       "           (cv1): Conv(\n",
       "             (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (cv2): Conv(\n",
       "             (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (5): Conv(\n",
       "       (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "       (act): SiLU(inplace=True)\n",
       "     )\n",
       "     (6): C2f(\n",
       "       (cv1): Conv(\n",
       "         (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (cv2): Conv(\n",
       "         (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (m): ModuleList(\n",
       "         (0-1): 2 x Bottleneck(\n",
       "           (cv1): Conv(\n",
       "             (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (cv2): Conv(\n",
       "             (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (7): Conv(\n",
       "       (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "       (act): SiLU(inplace=True)\n",
       "     )\n",
       "     (8): C2f(\n",
       "       (cv1): Conv(\n",
       "         (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (cv2): Conv(\n",
       "         (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (m): ModuleList(\n",
       "         (0): Bottleneck(\n",
       "           (cv1): Conv(\n",
       "             (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (cv2): Conv(\n",
       "             (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (9): SPPF(\n",
       "       (cv1): Conv(\n",
       "         (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (cv2): Conv(\n",
       "         (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "     )\n",
       "     (10): SEAttention(\n",
       "       (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "       (fc): Sequential(\n",
       "         (0): Linear(in_features=512, out_features=32, bias=False)\n",
       "         (1): ReLU(inplace=True)\n",
       "         (2): Linear(in_features=32, out_features=512, bias=False)\n",
       "         (3): Sigmoid()\n",
       "       )\n",
       "     )\n",
       "     (11): Upsample(scale_factor=2.0, mode='nearest')\n",
       "     (12): Concat()\n",
       "     (13): C2f(\n",
       "       (cv1): Conv(\n",
       "         (conv): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (cv2): Conv(\n",
       "         (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (m): ModuleList(\n",
       "         (0): Bottleneck(\n",
       "           (cv1): Conv(\n",
       "             (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (cv2): Conv(\n",
       "             (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (14): Upsample(scale_factor=2.0, mode='nearest')\n",
       "     (15): Concat()\n",
       "     (16): C2f(\n",
       "       (cv1): Conv(\n",
       "         (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (cv2): Conv(\n",
       "         (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (m): ModuleList(\n",
       "         (0): Bottleneck(\n",
       "           (cv1): Conv(\n",
       "             (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (cv2): Conv(\n",
       "             (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (17): Conv(\n",
       "       (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "       (act): SiLU(inplace=True)\n",
       "     )\n",
       "     (18): Concat()\n",
       "     (19): C2f(\n",
       "       (cv1): Conv(\n",
       "         (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (cv2): Conv(\n",
       "         (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (m): ModuleList(\n",
       "         (0): Bottleneck(\n",
       "           (cv1): Conv(\n",
       "             (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (cv2): Conv(\n",
       "             (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (20): Conv(\n",
       "       (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "       (act): SiLU(inplace=True)\n",
       "     )\n",
       "     (21): Concat()\n",
       "     (22): C2f(\n",
       "       (cv1): Conv(\n",
       "         (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (cv2): Conv(\n",
       "         (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "         (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "         (act): SiLU(inplace=True)\n",
       "       )\n",
       "       (m): ModuleList(\n",
       "         (0): Bottleneck(\n",
       "           (cv1): Conv(\n",
       "             (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (cv2): Conv(\n",
       "             (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (23): Detect(\n",
       "       (cv2): ModuleList(\n",
       "         (0): Sequential(\n",
       "           (0): Conv(\n",
       "             (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (1): Conv(\n",
       "             (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "         )\n",
       "         (1): Sequential(\n",
       "           (0): Conv(\n",
       "             (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (1): Conv(\n",
       "             (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "         )\n",
       "         (2): Sequential(\n",
       "           (0): Conv(\n",
       "             (conv): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (1): Conv(\n",
       "             (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "         )\n",
       "       )\n",
       "       (cv3): ModuleList(\n",
       "         (0): Sequential(\n",
       "           (0): Conv(\n",
       "             (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (1): Conv(\n",
       "             (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (2): Conv2d(128, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "         )\n",
       "         (1): Sequential(\n",
       "           (0): Conv(\n",
       "             (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (1): Conv(\n",
       "             (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (2): Conv2d(128, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "         )\n",
       "         (2): Sequential(\n",
       "           (0): Conv(\n",
       "             (conv): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (1): Conv(\n",
       "             (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "             (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "             (act): SiLU(inplace=True)\n",
       "           )\n",
       "           (2): Conv2d(128, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "         )\n",
       "       )\n",
       "       (dfl): DFL(\n",
       "         (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'ema': None,\n",
       " 'updates': None,\n",
       " 'optimizer': None,\n",
       " 'train_args': {'task': 'detect',\n",
       "  'mode': 'train',\n",
       "  'model': None,\n",
       "  'data': 'ultralytics/cfg/datasets/VOC_garbage.yaml',\n",
       "  'epochs': 300,\n",
       "  'patience': 100,\n",
       "  'batch': 16,\n",
       "  'imgsz': 640,\n",
       "  'save': True,\n",
       "  'save_period': -1,\n",
       "  'cache': None,\n",
       "  'device': '',\n",
       "  'workers': 4,\n",
       "  'project': 'runs\\\\train',\n",
       "  'name': 'exp',\n",
       "  'exist_ok': False,\n",
       "  'pretrained': True,\n",
       "  'optimizer': 'SGD',\n",
       "  'verbose': True,\n",
       "  'seed': 0,\n",
       "  'deterministic': True,\n",
       "  'single_cls': False,\n",
       "  'rect': False,\n",
       "  'cos_lr': False,\n",
       "  'close_mosaic': 0,\n",
       "  'resume': '',\n",
       "  'amp': True,\n",
       "  'fraction': 1.0,\n",
       "  'profile': False,\n",
       "  'freeze': 'None',\n",
       "  'overlap_mask': True,\n",
       "  'mask_ratio': 4,\n",
       "  'dropout': 0.0,\n",
       "  'val': True,\n",
       "  'split': 'val',\n",
       "  'save_json': False,\n",
       "  'save_hybrid': False,\n",
       "  'conf': None,\n",
       "  'iou': 0.7,\n",
       "  'max_det': 300,\n",
       "  'half': False,\n",
       "  'dnn': False,\n",
       "  'plots': True,\n",
       "  'source': None,\n",
       "  'show': False,\n",
       "  'save_txt': False,\n",
       "  'save_conf': False,\n",
       "  'save_crop': False,\n",
       "  'show_labels': True,\n",
       "  'show_conf': True,\n",
       "  'vid_stride': 1,\n",
       "  'stream_buffer': False,\n",
       "  'line_width': None,\n",
       "  'visualize': False,\n",
       "  'augment': False,\n",
       "  'agnostic_nms': False,\n",
       "  'classes': None,\n",
       "  'retina_masks': False,\n",
       "  'boxes': True,\n",
       "  'format': 'torchscript',\n",
       "  'keras': False,\n",
       "  'optimize': False,\n",
       "  'int8': False,\n",
       "  'dynamic': False,\n",
       "  'simplify': False,\n",
       "  'opset': None,\n",
       "  'workspace': 4,\n",
       "  'nms': False,\n",
       "  'lr0': 0.01,\n",
       "  'lrf': 0.01,\n",
       "  'momentum': 0.937,\n",
       "  'weight_decay': 0.0005,\n",
       "  'warmup_epochs': 3.0,\n",
       "  'warmup_momentum': 0.8,\n",
       "  'warmup_bias_lr': 0.1,\n",
       "  'box': 7.5,\n",
       "  'cls': 0.5,\n",
       "  'dfl': 1.5,\n",
       "  'pose': 12.0,\n",
       "  'kobj': 1.0,\n",
       "  'label_smoothing': 0.0,\n",
       "  'nbs': 64,\n",
       "  'hsv_h': 0.015,\n",
       "  'hsv_s': 0.7,\n",
       "  'hsv_v': 0.4,\n",
       "  'degrees': 0.0,\n",
       "  'translate': 0.1,\n",
       "  'scale': 0.5,\n",
       "  'shear': 0.0,\n",
       "  'perspective': 0.0,\n",
       "  'flipud': 0.0,\n",
       "  'fliplr': 0.5,\n",
       "  'mosaic': 1.0,\n",
       "  'mixup': 0.0,\n",
       "  'copy_paste': 0.0,\n",
       "  'cfg': 'ultralytics/cfg/default.yaml',\n",
       "  'tracker': 'botsort.yaml'},\n",
       " 'train_metrics': {'metrics/precision(B)': 0.79159,\n",
       "  'metrics/recall(B)': 0.5015,\n",
       "  'metrics/mAP50(B)': 0.56322,\n",
       "  'metrics/mAP50-95(B)': 0.47219,\n",
       "  'val/box_loss': 0.61076,\n",
       "  'val/cls_loss': 1.26556,\n",
       "  'val/dfl_loss': 1.16663,\n",
       "  'fitness': 0.48129},\n",
       " 'train_results': {'epoch': [1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20,\n",
       "   21,\n",
       "   22,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   30,\n",
       "   31,\n",
       "   32,\n",
       "   33,\n",
       "   34,\n",
       "   35,\n",
       "   36,\n",
       "   37,\n",
       "   38,\n",
       "   39,\n",
       "   40,\n",
       "   41,\n",
       "   42,\n",
       "   43,\n",
       "   44,\n",
       "   45,\n",
       "   46,\n",
       "   47,\n",
       "   48,\n",
       "   49,\n",
       "   50,\n",
       "   51,\n",
       "   52,\n",
       "   53,\n",
       "   54,\n",
       "   55,\n",
       "   56,\n",
       "   57,\n",
       "   58,\n",
       "   59,\n",
       "   60,\n",
       "   61,\n",
       "   62,\n",
       "   63,\n",
       "   64,\n",
       "   65,\n",
       "   66,\n",
       "   67,\n",
       "   68,\n",
       "   69,\n",
       "   70,\n",
       "   71,\n",
       "   72,\n",
       "   73,\n",
       "   74,\n",
       "   75,\n",
       "   76,\n",
       "   77,\n",
       "   78,\n",
       "   79,\n",
       "   80,\n",
       "   81,\n",
       "   82,\n",
       "   83,\n",
       "   84,\n",
       "   85,\n",
       "   86,\n",
       "   87,\n",
       "   88,\n",
       "   89,\n",
       "   90,\n",
       "   91,\n",
       "   92,\n",
       "   93,\n",
       "   94,\n",
       "   95,\n",
       "   96,\n",
       "   97,\n",
       "   98,\n",
       "   99,\n",
       "   100,\n",
       "   101,\n",
       "   102,\n",
       "   103,\n",
       "   104,\n",
       "   105,\n",
       "   106,\n",
       "   107,\n",
       "   108,\n",
       "   109,\n",
       "   110,\n",
       "   111,\n",
       "   112,\n",
       "   113,\n",
       "   114,\n",
       "   115,\n",
       "   116,\n",
       "   117,\n",
       "   118,\n",
       "   119,\n",
       "   120,\n",
       "   121,\n",
       "   122,\n",
       "   123,\n",
       "   124,\n",
       "   125,\n",
       "   126,\n",
       "   127,\n",
       "   128,\n",
       "   129,\n",
       "   130,\n",
       "   131,\n",
       "   132,\n",
       "   133,\n",
       "   134,\n",
       "   135,\n",
       "   136,\n",
       "   137,\n",
       "   138,\n",
       "   139,\n",
       "   140,\n",
       "   141,\n",
       "   142,\n",
       "   143,\n",
       "   144,\n",
       "   145,\n",
       "   146,\n",
       "   147,\n",
       "   148,\n",
       "   149,\n",
       "   150,\n",
       "   151,\n",
       "   152,\n",
       "   153,\n",
       "   154,\n",
       "   155,\n",
       "   156,\n",
       "   157,\n",
       "   158,\n",
       "   159,\n",
       "   160,\n",
       "   161,\n",
       "   162,\n",
       "   163,\n",
       "   164,\n",
       "   165,\n",
       "   166,\n",
       "   167,\n",
       "   168,\n",
       "   169,\n",
       "   170,\n",
       "   171,\n",
       "   172,\n",
       "   173,\n",
       "   174,\n",
       "   175,\n",
       "   176,\n",
       "   177,\n",
       "   178,\n",
       "   179,\n",
       "   180,\n",
       "   181,\n",
       "   182,\n",
       "   183,\n",
       "   184,\n",
       "   185,\n",
       "   186,\n",
       "   187,\n",
       "   188,\n",
       "   189,\n",
       "   190,\n",
       "   191,\n",
       "   192,\n",
       "   193,\n",
       "   194,\n",
       "   195,\n",
       "   196,\n",
       "   197,\n",
       "   198,\n",
       "   199,\n",
       "   200,\n",
       "   201,\n",
       "   202,\n",
       "   203,\n",
       "   204,\n",
       "   205,\n",
       "   206,\n",
       "   207,\n",
       "   208,\n",
       "   209,\n",
       "   210,\n",
       "   211,\n",
       "   212,\n",
       "   213,\n",
       "   214,\n",
       "   215,\n",
       "   216,\n",
       "   217,\n",
       "   218,\n",
       "   219,\n",
       "   220,\n",
       "   221,\n",
       "   222,\n",
       "   223,\n",
       "   224,\n",
       "   225,\n",
       "   226,\n",
       "   227,\n",
       "   228,\n",
       "   229,\n",
       "   230,\n",
       "   231,\n",
       "   232,\n",
       "   233,\n",
       "   234,\n",
       "   235,\n",
       "   236,\n",
       "   237,\n",
       "   238,\n",
       "   239],\n",
       "  'train/box_loss': [3.1358,\n",
       "   2.8358,\n",
       "   2.3286,\n",
       "   1.7991,\n",
       "   1.5476,\n",
       "   1.4199,\n",
       "   1.3452,\n",
       "   1.2783,\n",
       "   1.2444,\n",
       "   1.2167,\n",
       "   1.1848,\n",
       "   1.1563,\n",
       "   1.13,\n",
       "   1.1077,\n",
       "   1.0911,\n",
       "   1.0849,\n",
       "   1.049,\n",
       "   1.0403,\n",
       "   1.0226,\n",
       "   1.0146,\n",
       "   1.0115,\n",
       "   0.98223,\n",
       "   0.97794,\n",
       "   0.9647,\n",
       "   0.96842,\n",
       "   0.96471,\n",
       "   0.94031,\n",
       "   0.9327,\n",
       "   0.93986,\n",
       "   0.91555,\n",
       "   0.91449,\n",
       "   0.91021,\n",
       "   0.89148,\n",
       "   0.89113,\n",
       "   0.87731,\n",
       "   0.88584,\n",
       "   0.87041,\n",
       "   0.87005,\n",
       "   0.86087,\n",
       "   0.85823,\n",
       "   0.83647,\n",
       "   0.84799,\n",
       "   0.82923,\n",
       "   0.82572,\n",
       "   0.82593,\n",
       "   0.82341,\n",
       "   0.81126,\n",
       "   0.80785,\n",
       "   0.81485,\n",
       "   0.80244,\n",
       "   0.80225,\n",
       "   0.79018,\n",
       "   0.78885,\n",
       "   0.78185,\n",
       "   0.77983,\n",
       "   0.78383,\n",
       "   0.76909,\n",
       "   0.77252,\n",
       "   0.76608,\n",
       "   0.76236,\n",
       "   0.76456,\n",
       "   0.75536,\n",
       "   0.74303,\n",
       "   0.75147,\n",
       "   0.74712,\n",
       "   0.73839,\n",
       "   0.7371,\n",
       "   0.72463,\n",
       "   0.73186,\n",
       "   0.72258,\n",
       "   0.72486,\n",
       "   0.71788,\n",
       "   0.70715,\n",
       "   0.72054,\n",
       "   0.70997,\n",
       "   0.70594,\n",
       "   0.70664,\n",
       "   0.69169,\n",
       "   0.69606,\n",
       "   0.69363,\n",
       "   0.68722,\n",
       "   0.69036,\n",
       "   0.68559,\n",
       "   0.68421,\n",
       "   0.68385,\n",
       "   0.67389,\n",
       "   0.68274,\n",
       "   0.66112,\n",
       "   0.66993,\n",
       "   0.66037,\n",
       "   0.65599,\n",
       "   0.66938,\n",
       "   0.67148,\n",
       "   0.66351,\n",
       "   0.65509,\n",
       "   0.65743,\n",
       "   0.64826,\n",
       "   0.65738,\n",
       "   0.65384,\n",
       "   0.64381,\n",
       "   0.64535,\n",
       "   0.63857,\n",
       "   0.64896,\n",
       "   0.63744,\n",
       "   0.63138,\n",
       "   0.63628,\n",
       "   0.6284,\n",
       "   0.62989,\n",
       "   0.62212,\n",
       "   0.62763,\n",
       "   0.61999,\n",
       "   0.61497,\n",
       "   0.62278,\n",
       "   0.61428,\n",
       "   0.6102,\n",
       "   0.60904,\n",
       "   0.60725,\n",
       "   0.60494,\n",
       "   0.60026,\n",
       "   0.60325,\n",
       "   0.60498,\n",
       "   0.60364,\n",
       "   0.60217,\n",
       "   0.59848,\n",
       "   0.60085,\n",
       "   0.59898,\n",
       "   0.58218,\n",
       "   0.58957,\n",
       "   0.58057,\n",
       "   0.59077,\n",
       "   0.57595,\n",
       "   0.57945,\n",
       "   0.57941,\n",
       "   0.5768,\n",
       "   0.57806,\n",
       "   0.57426,\n",
       "   0.56704,\n",
       "   0.57198,\n",
       "   0.56924,\n",
       "   0.56858,\n",
       "   0.56112,\n",
       "   0.56701,\n",
       "   0.56078,\n",
       "   0.56801,\n",
       "   0.56143,\n",
       "   0.56018,\n",
       "   0.56291,\n",
       "   0.55464,\n",
       "   0.54874,\n",
       "   0.55699,\n",
       "   0.55588,\n",
       "   0.55862,\n",
       "   0.54686,\n",
       "   0.54219,\n",
       "   0.54482,\n",
       "   0.53868,\n",
       "   0.54351,\n",
       "   0.53706,\n",
       "   0.54077,\n",
       "   0.5438,\n",
       "   0.53756,\n",
       "   0.53129,\n",
       "   0.5329,\n",
       "   0.53815,\n",
       "   0.53325,\n",
       "   0.52704,\n",
       "   0.52654,\n",
       "   0.52368,\n",
       "   0.52494,\n",
       "   0.5196,\n",
       "   0.5204,\n",
       "   0.5275,\n",
       "   0.52423,\n",
       "   0.51088,\n",
       "   0.51005,\n",
       "   0.50927,\n",
       "   0.51288,\n",
       "   0.49974,\n",
       "   0.50932,\n",
       "   0.5075,\n",
       "   0.51743,\n",
       "   0.51257,\n",
       "   0.50693,\n",
       "   0.5114,\n",
       "   0.50479,\n",
       "   0.50476,\n",
       "   0.49642,\n",
       "   0.49972,\n",
       "   0.49959,\n",
       "   0.4961,\n",
       "   0.49054,\n",
       "   0.49217,\n",
       "   0.5003,\n",
       "   0.49429,\n",
       "   0.48893,\n",
       "   0.49428,\n",
       "   0.48446,\n",
       "   0.48623,\n",
       "   0.48646,\n",
       "   0.48497,\n",
       "   0.48459,\n",
       "   0.47955,\n",
       "   0.48038,\n",
       "   0.47592,\n",
       "   0.48238,\n",
       "   0.47548,\n",
       "   0.48209,\n",
       "   0.47094,\n",
       "   0.47435,\n",
       "   0.48319,\n",
       "   0.47066,\n",
       "   0.47347,\n",
       "   0.47388,\n",
       "   0.46602,\n",
       "   0.47186,\n",
       "   0.47105,\n",
       "   0.46029,\n",
       "   0.45568,\n",
       "   0.46333,\n",
       "   0.46433,\n",
       "   0.46392,\n",
       "   0.45457,\n",
       "   0.45281,\n",
       "   0.45729,\n",
       "   0.45722,\n",
       "   0.45058,\n",
       "   0.44942,\n",
       "   0.44872,\n",
       "   0.45732,\n",
       "   0.44944,\n",
       "   0.45128,\n",
       "   0.44355,\n",
       "   0.44335,\n",
       "   0.44363,\n",
       "   0.4438,\n",
       "   0.44075,\n",
       "   0.44148,\n",
       "   0.44543,\n",
       "   0.44006],\n",
       "  'train/cls_loss': [5.3206,\n",
       "   4.9784,\n",
       "   4.5154,\n",
       "   4.0342,\n",
       "   3.6919,\n",
       "   3.4545,\n",
       "   3.2941,\n",
       "   3.143,\n",
       "   3.045,\n",
       "   2.997,\n",
       "   2.8797,\n",
       "   2.8213,\n",
       "   2.7576,\n",
       "   2.7039,\n",
       "   2.6457,\n",
       "   2.5869,\n",
       "   2.5423,\n",
       "   2.4978,\n",
       "   2.4475,\n",
       "   2.4145,\n",
       "   2.3923,\n",
       "   2.3357,\n",
       "   2.3049,\n",
       "   2.2754,\n",
       "   2.2298,\n",
       "   2.2114,\n",
       "   2.1763,\n",
       "   2.1519,\n",
       "   2.137,\n",
       "   2.0864,\n",
       "   2.0884,\n",
       "   2.0614,\n",
       "   2.0065,\n",
       "   2.0017,\n",
       "   1.9808,\n",
       "   1.9774,\n",
       "   1.9352,\n",
       "   1.9138,\n",
       "   1.8803,\n",
       "   1.8909,\n",
       "   1.8364,\n",
       "   1.8488,\n",
       "   1.7957,\n",
       "   1.7933,\n",
       "   1.7732,\n",
       "   1.7521,\n",
       "   1.7291,\n",
       "   1.7119,\n",
       "   1.7028,\n",
       "   1.6955,\n",
       "   1.6598,\n",
       "   1.6629,\n",
       "   1.6336,\n",
       "   1.6175,\n",
       "   1.6221,\n",
       "   1.5963,\n",
       "   1.5738,\n",
       "   1.5883,\n",
       "   1.562,\n",
       "   1.5368,\n",
       "   1.5208,\n",
       "   1.5182,\n",
       "   1.4804,\n",
       "   1.487,\n",
       "   1.4779,\n",
       "   1.4611,\n",
       "   1.44,\n",
       "   1.4332,\n",
       "   1.4224,\n",
       "   1.4047,\n",
       "   1.4013,\n",
       "   1.3975,\n",
       "   1.3775,\n",
       "   1.3631,\n",
       "   1.355,\n",
       "   1.3247,\n",
       "   1.3324,\n",
       "   1.3137,\n",
       "   1.2997,\n",
       "   1.2879,\n",
       "   1.275,\n",
       "   1.289,\n",
       "   1.2823,\n",
       "   1.2754,\n",
       "   1.2627,\n",
       "   1.2422,\n",
       "   1.2503,\n",
       "   1.2055,\n",
       "   1.2041,\n",
       "   1.19,\n",
       "   1.1951,\n",
       "   1.1792,\n",
       "   1.1896,\n",
       "   1.1727,\n",
       "   1.1479,\n",
       "   1.1438,\n",
       "   1.1302,\n",
       "   1.1542,\n",
       "   1.1453,\n",
       "   1.1289,\n",
       "   1.1138,\n",
       "   1.1001,\n",
       "   1.1043,\n",
       "   1.0921,\n",
       "   1.0769,\n",
       "   1.0892,\n",
       "   1.0758,\n",
       "   1.0652,\n",
       "   1.0484,\n",
       "   1.0538,\n",
       "   1.0422,\n",
       "   1.0333,\n",
       "   1.0509,\n",
       "   1.0166,\n",
       "   1.0157,\n",
       "   1.0157,\n",
       "   1.0004,\n",
       "   0.9947,\n",
       "   0.97942,\n",
       "   0.98644,\n",
       "   0.994,\n",
       "   0.97602,\n",
       "   0.97662,\n",
       "   0.97335,\n",
       "   0.96476,\n",
       "   0.9556,\n",
       "   0.93735,\n",
       "   0.94074,\n",
       "   0.91636,\n",
       "   0.92306,\n",
       "   0.91032,\n",
       "   0.916,\n",
       "   0.91344,\n",
       "   0.91318,\n",
       "   0.91373,\n",
       "   0.90927,\n",
       "   0.88358,\n",
       "   0.87717,\n",
       "   0.88962,\n",
       "   0.87733,\n",
       "   0.86346,\n",
       "   0.8699,\n",
       "   0.8631,\n",
       "   0.86729,\n",
       "   0.85323,\n",
       "   0.86408,\n",
       "   0.85344,\n",
       "   0.83398,\n",
       "   0.82361,\n",
       "   0.8434,\n",
       "   0.83263,\n",
       "   0.8335,\n",
       "   0.80744,\n",
       "   0.82035,\n",
       "   0.80571,\n",
       "   0.80738,\n",
       "   0.81548,\n",
       "   0.79576,\n",
       "   0.79781,\n",
       "   0.79354,\n",
       "   0.79979,\n",
       "   0.78496,\n",
       "   0.7684,\n",
       "   0.78111,\n",
       "   0.77893,\n",
       "   0.77373,\n",
       "   0.75546,\n",
       "   0.76681,\n",
       "   0.76204,\n",
       "   0.75491,\n",
       "   0.75468,\n",
       "   0.75931,\n",
       "   0.75135,\n",
       "   0.74218,\n",
       "   0.72425,\n",
       "   0.7262,\n",
       "   0.73948,\n",
       "   0.70397,\n",
       "   0.71662,\n",
       "   0.70051,\n",
       "   0.73403,\n",
       "   0.71867,\n",
       "   0.70859,\n",
       "   0.70911,\n",
       "   0.70785,\n",
       "   0.70152,\n",
       "   0.68615,\n",
       "   0.70039,\n",
       "   0.69062,\n",
       "   0.69098,\n",
       "   0.681,\n",
       "   0.68159,\n",
       "   0.68222,\n",
       "   0.68153,\n",
       "   0.68068,\n",
       "   0.68766,\n",
       "   0.6612,\n",
       "   0.65641,\n",
       "   0.66598,\n",
       "   0.66502,\n",
       "   0.6546,\n",
       "   0.65644,\n",
       "   0.6551,\n",
       "   0.64886,\n",
       "   0.6486,\n",
       "   0.64006,\n",
       "   0.64532,\n",
       "   0.64187,\n",
       "   0.63848,\n",
       "   0.64819,\n",
       "   0.63279,\n",
       "   0.63709,\n",
       "   0.63115,\n",
       "   0.62129,\n",
       "   0.62817,\n",
       "   0.61773,\n",
       "   0.60736,\n",
       "   0.61655,\n",
       "   0.61331,\n",
       "   0.61485,\n",
       "   0.61158,\n",
       "   0.60393,\n",
       "   0.59204,\n",
       "   0.60873,\n",
       "   0.5923,\n",
       "   0.59018,\n",
       "   0.59333,\n",
       "   0.58908,\n",
       "   0.59832,\n",
       "   0.58445,\n",
       "   0.58586,\n",
       "   0.58193,\n",
       "   0.57747,\n",
       "   0.57116,\n",
       "   0.56681,\n",
       "   0.56399,\n",
       "   0.56943,\n",
       "   0.57768,\n",
       "   0.57274],\n",
       "  'train/dfl_loss': [4.0448,\n",
       "   3.4208,\n",
       "   2.8632,\n",
       "   2.3595,\n",
       "   2.0929,\n",
       "   1.9562,\n",
       "   1.8805,\n",
       "   1.8025,\n",
       "   1.7739,\n",
       "   1.7463,\n",
       "   1.7111,\n",
       "   1.6884,\n",
       "   1.6552,\n",
       "   1.634,\n",
       "   1.6141,\n",
       "   1.6073,\n",
       "   1.5821,\n",
       "   1.5649,\n",
       "   1.5564,\n",
       "   1.5381,\n",
       "   1.5325,\n",
       "   1.513,\n",
       "   1.5089,\n",
       "   1.4946,\n",
       "   1.4885,\n",
       "   1.4781,\n",
       "   1.4722,\n",
       "   1.4611,\n",
       "   1.4605,\n",
       "   1.449,\n",
       "   1.4472,\n",
       "   1.4364,\n",
       "   1.4227,\n",
       "   1.4186,\n",
       "   1.4091,\n",
       "   1.4169,\n",
       "   1.4109,\n",
       "   1.4042,\n",
       "   1.3964,\n",
       "   1.3964,\n",
       "   1.3747,\n",
       "   1.385,\n",
       "   1.37,\n",
       "   1.3631,\n",
       "   1.3667,\n",
       "   1.3564,\n",
       "   1.3486,\n",
       "   1.3434,\n",
       "   1.3517,\n",
       "   1.3423,\n",
       "   1.3376,\n",
       "   1.3254,\n",
       "   1.3289,\n",
       "   1.3243,\n",
       "   1.3221,\n",
       "   1.3256,\n",
       "   1.3086,\n",
       "   1.3187,\n",
       "   1.3124,\n",
       "   1.3059,\n",
       "   1.308,\n",
       "   1.3006,\n",
       "   1.2943,\n",
       "   1.2969,\n",
       "   1.2918,\n",
       "   1.2832,\n",
       "   1.2802,\n",
       "   1.2708,\n",
       "   1.2782,\n",
       "   1.2699,\n",
       "   1.2709,\n",
       "   1.2709,\n",
       "   1.2604,\n",
       "   1.2708,\n",
       "   1.2616,\n",
       "   1.2578,\n",
       "   1.2609,\n",
       "   1.2488,\n",
       "   1.2463,\n",
       "   1.2483,\n",
       "   1.2397,\n",
       "   1.2496,\n",
       "   1.2414,\n",
       "   1.2428,\n",
       "   1.2359,\n",
       "   1.2319,\n",
       "   1.2347,\n",
       "   1.219,\n",
       "   1.226,\n",
       "   1.2164,\n",
       "   1.2174,\n",
       "   1.2253,\n",
       "   1.227,\n",
       "   1.2171,\n",
       "   1.2117,\n",
       "   1.2087,\n",
       "   1.2005,\n",
       "   1.2124,\n",
       "   1.2096,\n",
       "   1.2053,\n",
       "   1.1974,\n",
       "   1.1965,\n",
       "   1.2017,\n",
       "   1.1968,\n",
       "   1.1883,\n",
       "   1.2006,\n",
       "   1.184,\n",
       "   1.1892,\n",
       "   1.1823,\n",
       "   1.188,\n",
       "   1.1754,\n",
       "   1.1767,\n",
       "   1.1864,\n",
       "   1.1742,\n",
       "   1.171,\n",
       "   1.1684,\n",
       "   1.1683,\n",
       "   1.1646,\n",
       "   1.1613,\n",
       "   1.1686,\n",
       "   1.1693,\n",
       "   1.1643,\n",
       "   1.1674,\n",
       "   1.164,\n",
       "   1.1615,\n",
       "   1.1605,\n",
       "   1.1462,\n",
       "   1.156,\n",
       "   1.1459,\n",
       "   1.1541,\n",
       "   1.1491,\n",
       "   1.15,\n",
       "   1.1469,\n",
       "   1.1456,\n",
       "   1.1447,\n",
       "   1.139,\n",
       "   1.1364,\n",
       "   1.1389,\n",
       "   1.138,\n",
       "   1.1376,\n",
       "   1.1303,\n",
       "   1.1366,\n",
       "   1.1307,\n",
       "   1.1317,\n",
       "   1.1276,\n",
       "   1.1348,\n",
       "   1.1301,\n",
       "   1.1253,\n",
       "   1.1237,\n",
       "   1.1311,\n",
       "   1.1285,\n",
       "   1.1274,\n",
       "   1.1186,\n",
       "   1.1184,\n",
       "   1.1155,\n",
       "   1.1145,\n",
       "   1.118,\n",
       "   1.1105,\n",
       "   1.1143,\n",
       "   1.1158,\n",
       "   1.1138,\n",
       "   1.1038,\n",
       "   1.1047,\n",
       "   1.111,\n",
       "   1.1074,\n",
       "   1.1022,\n",
       "   1.1041,\n",
       "   1.0978,\n",
       "   1.1004,\n",
       "   1.1019,\n",
       "   1.0977,\n",
       "   1.0999,\n",
       "   1.0999,\n",
       "   1.0943,\n",
       "   1.0882,\n",
       "   1.0913,\n",
       "   1.0926,\n",
       "   1.0841,\n",
       "   1.091,\n",
       "   1.0843,\n",
       "   1.0948,\n",
       "   1.0897,\n",
       "   1.0877,\n",
       "   1.0895,\n",
       "   1.0878,\n",
       "   1.087,\n",
       "   1.0797,\n",
       "   1.0808,\n",
       "   1.0847,\n",
       "   1.0791,\n",
       "   1.0768,\n",
       "   1.0741,\n",
       "   1.0795,\n",
       "   1.0772,\n",
       "   1.0719,\n",
       "   1.0788,\n",
       "   1.0686,\n",
       "   1.0692,\n",
       "   1.0725,\n",
       "   1.0681,\n",
       "   1.0689,\n",
       "   1.0659,\n",
       "   1.0664,\n",
       "   1.0644,\n",
       "   1.0648,\n",
       "   1.0624,\n",
       "   1.0688,\n",
       "   1.0616,\n",
       "   1.0632,\n",
       "   1.0709,\n",
       "   1.0599,\n",
       "   1.0615,\n",
       "   1.0627,\n",
       "   1.0569,\n",
       "   1.0577,\n",
       "   1.0595,\n",
       "   1.0497,\n",
       "   1.0503,\n",
       "   1.0481,\n",
       "   1.0574,\n",
       "   1.0568,\n",
       "   1.0493,\n",
       "   1.0464,\n",
       "   1.0489,\n",
       "   1.0492,\n",
       "   1.0444,\n",
       "   1.0423,\n",
       "   1.0419,\n",
       "   1.0486,\n",
       "   1.0424,\n",
       "   1.0468,\n",
       "   1.0375,\n",
       "   1.0376,\n",
       "   1.0397,\n",
       "   1.04,\n",
       "   1.034,\n",
       "   1.0399,\n",
       "   1.0387,\n",
       "   1.0341],\n",
       "  'metrics/precision(B)': [0.00094,\n",
       "   0.16034,\n",
       "   0.32412,\n",
       "   0.41217,\n",
       "   0.36754,\n",
       "   0.52971,\n",
       "   0.44164,\n",
       "   0.5168,\n",
       "   0.38925,\n",
       "   0.58216,\n",
       "   0.4605,\n",
       "   0.60367,\n",
       "   0.55952,\n",
       "   0.56268,\n",
       "   0.60185,\n",
       "   0.54941,\n",
       "   0.50722,\n",
       "   0.68191,\n",
       "   0.55161,\n",
       "   0.54569,\n",
       "   0.63113,\n",
       "   0.6308,\n",
       "   0.63463,\n",
       "   0.58377,\n",
       "   0.65469,\n",
       "   0.59202,\n",
       "   0.68592,\n",
       "   0.73176,\n",
       "   0.56458,\n",
       "   0.65305,\n",
       "   0.68715,\n",
       "   0.6995,\n",
       "   0.59802,\n",
       "   0.68643,\n",
       "   0.67789,\n",
       "   0.59415,\n",
       "   0.59935,\n",
       "   0.72524,\n",
       "   0.69422,\n",
       "   0.61268,\n",
       "   0.5795,\n",
       "   0.5988,\n",
       "   0.53921,\n",
       "   0.57018,\n",
       "   0.7174,\n",
       "   0.75405,\n",
       "   0.66352,\n",
       "   0.6353,\n",
       "   0.63888,\n",
       "   0.66011,\n",
       "   0.50513,\n",
       "   0.4865,\n",
       "   0.76722,\n",
       "   0.66191,\n",
       "   0.64256,\n",
       "   0.73756,\n",
       "   0.70274,\n",
       "   0.64779,\n",
       "   0.53692,\n",
       "   0.5441,\n",
       "   0.56574,\n",
       "   0.66552,\n",
       "   0.59311,\n",
       "   0.72454,\n",
       "   0.58924,\n",
       "   0.55896,\n",
       "   0.67664,\n",
       "   0.72773,\n",
       "   0.74276,\n",
       "   0.54995,\n",
       "   0.72012,\n",
       "   0.66686,\n",
       "   0.65121,\n",
       "   0.66694,\n",
       "   0.70965,\n",
       "   0.6259,\n",
       "   0.59205,\n",
       "   0.53947,\n",
       "   0.66418,\n",
       "   0.65086,\n",
       "   0.58915,\n",
       "   0.72561,\n",
       "   0.65138,\n",
       "   0.6036,\n",
       "   0.62169,\n",
       "   0.6612,\n",
       "   0.67354,\n",
       "   0.6393,\n",
       "   0.65848,\n",
       "   0.71139,\n",
       "   0.64294,\n",
       "   0.60847,\n",
       "   0.63547,\n",
       "   0.59855,\n",
       "   0.64795,\n",
       "   0.71842,\n",
       "   0.59278,\n",
       "   0.65079,\n",
       "   0.70457,\n",
       "   0.66473,\n",
       "   0.70945,\n",
       "   0.71591,\n",
       "   0.715,\n",
       "   0.65597,\n",
       "   0.68548,\n",
       "   0.65868,\n",
       "   0.57167,\n",
       "   0.70353,\n",
       "   0.61892,\n",
       "   0.64924,\n",
       "   0.59927,\n",
       "   0.60706,\n",
       "   0.61729,\n",
       "   0.64806,\n",
       "   0.63452,\n",
       "   0.68335,\n",
       "   0.65867,\n",
       "   0.67204,\n",
       "   0.61629,\n",
       "   0.75805,\n",
       "   0.56548,\n",
       "   0.63238,\n",
       "   0.74347,\n",
       "   0.72725,\n",
       "   0.69372,\n",
       "   0.75271,\n",
       "   0.64485,\n",
       "   0.7673,\n",
       "   0.76471,\n",
       "   0.67128,\n",
       "   0.57846,\n",
       "   0.76098,\n",
       "   0.74233,\n",
       "   0.79919,\n",
       "   0.73874,\n",
       "   0.76123,\n",
       "   0.70262,\n",
       "   0.66554,\n",
       "   0.68282,\n",
       "   0.66576,\n",
       "   0.74975,\n",
       "   0.74326,\n",
       "   0.77558,\n",
       "   0.66857,\n",
       "   0.77329,\n",
       "   0.74178,\n",
       "   0.77012,\n",
       "   0.63949,\n",
       "   0.68932,\n",
       "   0.69466,\n",
       "   0.65203,\n",
       "   0.68383,\n",
       "   0.73359,\n",
       "   0.745,\n",
       "   0.74681,\n",
       "   0.74705,\n",
       "   0.74309,\n",
       "   0.73079,\n",
       "   0.73273,\n",
       "   0.64513,\n",
       "   0.72966,\n",
       "   0.74706,\n",
       "   0.75685,\n",
       "   0.76712,\n",
       "   0.75928,\n",
       "   0.76021,\n",
       "   0.77227,\n",
       "   0.76927,\n",
       "   0.76314,\n",
       "   0.76861,\n",
       "   0.76365,\n",
       "   0.76342,\n",
       "   0.68428,\n",
       "   0.76306,\n",
       "   0.7326,\n",
       "   0.71466,\n",
       "   0.71731,\n",
       "   0.78612,\n",
       "   0.7839,\n",
       "   0.79646,\n",
       "   0.79538,\n",
       "   0.79704,\n",
       "   0.80494,\n",
       "   0.7934,\n",
       "   0.75289,\n",
       "   0.74256,\n",
       "   0.75343,\n",
       "   0.75274,\n",
       "   0.7564,\n",
       "   0.76503,\n",
       "   0.71172,\n",
       "   0.72571,\n",
       "   0.71822,\n",
       "   0.71787,\n",
       "   0.76115,\n",
       "   0.75294,\n",
       "   0.72093,\n",
       "   0.71739,\n",
       "   0.7187,\n",
       "   0.68214,\n",
       "   0.72169,\n",
       "   0.72108,\n",
       "   0.757,\n",
       "   0.76747,\n",
       "   0.77071,\n",
       "   0.75857,\n",
       "   0.76305,\n",
       "   0.77123,\n",
       "   0.76798,\n",
       "   0.78266,\n",
       "   0.7784,\n",
       "   0.75702,\n",
       "   0.75732,\n",
       "   0.78303,\n",
       "   0.78189,\n",
       "   0.74048,\n",
       "   0.73701,\n",
       "   0.73406,\n",
       "   0.76843,\n",
       "   0.77408,\n",
       "   0.77818,\n",
       "   0.7796,\n",
       "   0.79108,\n",
       "   0.78315,\n",
       "   0.7872,\n",
       "   0.7793,\n",
       "   0.79404,\n",
       "   0.79655,\n",
       "   0.75374,\n",
       "   0.75367,\n",
       "   0.76297,\n",
       "   0.77079,\n",
       "   0.77702,\n",
       "   0.77942,\n",
       "   0.78413,\n",
       "   0.77067,\n",
       "   0.79242,\n",
       "   0.75374,\n",
       "   0.79159],\n",
       "  'metrics/recall(B)': [0.02225,\n",
       "   0.07428,\n",
       "   0.01964,\n",
       "   0.08855,\n",
       "   0.11023,\n",
       "   0.12066,\n",
       "   0.16639,\n",
       "   0.18668,\n",
       "   0.20609,\n",
       "   0.18168,\n",
       "   0.23328,\n",
       "   0.22789,\n",
       "   0.22957,\n",
       "   0.26337,\n",
       "   0.2378,\n",
       "   0.2693,\n",
       "   0.30462,\n",
       "   0.24976,\n",
       "   0.27564,\n",
       "   0.26486,\n",
       "   0.26525,\n",
       "   0.29008,\n",
       "   0.27402,\n",
       "   0.30454,\n",
       "   0.28435,\n",
       "   0.30312,\n",
       "   0.31958,\n",
       "   0.28262,\n",
       "   0.31846,\n",
       "   0.29973,\n",
       "   0.31377,\n",
       "   0.31052,\n",
       "   0.31844,\n",
       "   0.31028,\n",
       "   0.33157,\n",
       "   0.34674,\n",
       "   0.35682,\n",
       "   0.33809,\n",
       "   0.36414,\n",
       "   0.33494,\n",
       "   0.37574,\n",
       "   0.36443,\n",
       "   0.38341,\n",
       "   0.36305,\n",
       "   0.37958,\n",
       "   0.35225,\n",
       "   0.42191,\n",
       "   0.36963,\n",
       "   0.3713,\n",
       "   0.38907,\n",
       "   0.41666,\n",
       "   0.45035,\n",
       "   0.37851,\n",
       "   0.38893,\n",
       "   0.40517,\n",
       "   0.37381,\n",
       "   0.41219,\n",
       "   0.42771,\n",
       "   0.45202,\n",
       "   0.46979,\n",
       "   0.43525,\n",
       "   0.41371,\n",
       "   0.43108,\n",
       "   0.37675,\n",
       "   0.43699,\n",
       "   0.42739,\n",
       "   0.40514,\n",
       "   0.41329,\n",
       "   0.43638,\n",
       "   0.46524,\n",
       "   0.45028,\n",
       "   0.41172,\n",
       "   0.45121,\n",
       "   0.44494,\n",
       "   0.425,\n",
       "   0.4343,\n",
       "   0.45045,\n",
       "   0.48992,\n",
       "   0.45665,\n",
       "   0.46287,\n",
       "   0.46586,\n",
       "   0.4549,\n",
       "   0.4721,\n",
       "   0.48287,\n",
       "   0.48332,\n",
       "   0.45884,\n",
       "   0.44741,\n",
       "   0.48948,\n",
       "   0.48837,\n",
       "   0.4567,\n",
       "   0.47996,\n",
       "   0.46463,\n",
       "   0.48308,\n",
       "   0.506,\n",
       "   0.46603,\n",
       "   0.47236,\n",
       "   0.47891,\n",
       "   0.48166,\n",
       "   0.47072,\n",
       "   0.49586,\n",
       "   0.47736,\n",
       "   0.46693,\n",
       "   0.46212,\n",
       "   0.47178,\n",
       "   0.50143,\n",
       "   0.48354,\n",
       "   0.48885,\n",
       "   0.47056,\n",
       "   0.48379,\n",
       "   0.48109,\n",
       "   0.48558,\n",
       "   0.50448,\n",
       "   0.50393,\n",
       "   0.49891,\n",
       "   0.50661,\n",
       "   0.47717,\n",
       "   0.49907,\n",
       "   0.47643,\n",
       "   0.50908,\n",
       "   0.47119,\n",
       "   0.53519,\n",
       "   0.50455,\n",
       "   0.49909,\n",
       "   0.49428,\n",
       "   0.48121,\n",
       "   0.45967,\n",
       "   0.50621,\n",
       "   0.46702,\n",
       "   0.49003,\n",
       "   0.48422,\n",
       "   0.52683,\n",
       "   0.48504,\n",
       "   0.47915,\n",
       "   0.48361,\n",
       "   0.48666,\n",
       "   0.47847,\n",
       "   0.49487,\n",
       "   0.48751,\n",
       "   0.47839,\n",
       "   0.47879,\n",
       "   0.46732,\n",
       "   0.47976,\n",
       "   0.47627,\n",
       "   0.49687,\n",
       "   0.47928,\n",
       "   0.48373,\n",
       "   0.46682,\n",
       "   0.50289,\n",
       "   0.50459,\n",
       "   0.51914,\n",
       "   0.51371,\n",
       "   0.49539,\n",
       "   0.50242,\n",
       "   0.51157,\n",
       "   0.52153,\n",
       "   0.51233,\n",
       "   0.51987,\n",
       "   0.50623,\n",
       "   0.49369,\n",
       "   0.52585,\n",
       "   0.49504,\n",
       "   0.51584,\n",
       "   0.50733,\n",
       "   0.49428,\n",
       "   0.50539,\n",
       "   0.50012,\n",
       "   0.49945,\n",
       "   0.49777,\n",
       "   0.49839,\n",
       "   0.48367,\n",
       "   0.49431,\n",
       "   0.49217,\n",
       "   0.5089,\n",
       "   0.49515,\n",
       "   0.50178,\n",
       "   0.50199,\n",
       "   0.5007,\n",
       "   0.47474,\n",
       "   0.48249,\n",
       "   0.48122,\n",
       "   0.47983,\n",
       "   0.49233,\n",
       "   0.48789,\n",
       "   0.49412,\n",
       "   0.50051,\n",
       "   0.50603,\n",
       "   0.49733,\n",
       "   0.50426,\n",
       "   0.50249,\n",
       "   0.4912,\n",
       "   0.50862,\n",
       "   0.50469,\n",
       "   0.50752,\n",
       "   0.51284,\n",
       "   0.50377,\n",
       "   0.50834,\n",
       "   0.51511,\n",
       "   0.51125,\n",
       "   0.51423,\n",
       "   0.51455,\n",
       "   0.50969,\n",
       "   0.51097,\n",
       "   0.50682,\n",
       "   0.50514,\n",
       "   0.49745,\n",
       "   0.50183,\n",
       "   0.5051,\n",
       "   0.50201,\n",
       "   0.50074,\n",
       "   0.50252,\n",
       "   0.50275,\n",
       "   0.50737,\n",
       "   0.5046,\n",
       "   0.49892,\n",
       "   0.49908,\n",
       "   0.50237,\n",
       "   0.50679,\n",
       "   0.51,\n",
       "   0.50358,\n",
       "   0.50161,\n",
       "   0.49774,\n",
       "   0.49697,\n",
       "   0.49409,\n",
       "   0.49769,\n",
       "   0.49807,\n",
       "   0.50471,\n",
       "   0.50075,\n",
       "   0.50095,\n",
       "   0.51348,\n",
       "   0.51516,\n",
       "   0.51257,\n",
       "   0.50918,\n",
       "   0.50695,\n",
       "   0.50723,\n",
       "   0.50591,\n",
       "   0.50738,\n",
       "   0.50124,\n",
       "   0.50849,\n",
       "   0.5015],\n",
       "  'metrics/mAP50(B)': [0.00072,\n",
       "   0.00336,\n",
       "   0.00646,\n",
       "   0.02971,\n",
       "   0.07517,\n",
       "   0.09066,\n",
       "   0.13442,\n",
       "   0.1472,\n",
       "   0.17601,\n",
       "   0.1858,\n",
       "   0.20116,\n",
       "   0.21767,\n",
       "   0.2307,\n",
       "   0.23669,\n",
       "   0.25056,\n",
       "   0.23844,\n",
       "   0.26155,\n",
       "   0.25995,\n",
       "   0.27301,\n",
       "   0.27191,\n",
       "   0.27449,\n",
       "   0.30559,\n",
       "   0.30213,\n",
       "   0.32028,\n",
       "   0.31762,\n",
       "   0.32717,\n",
       "   0.34161,\n",
       "   0.33947,\n",
       "   0.32688,\n",
       "   0.34039,\n",
       "   0.37834,\n",
       "   0.35585,\n",
       "   0.34369,\n",
       "   0.35796,\n",
       "   0.35332,\n",
       "   0.36408,\n",
       "   0.39045,\n",
       "   0.3805,\n",
       "   0.40776,\n",
       "   0.36848,\n",
       "   0.39622,\n",
       "   0.38923,\n",
       "   0.40108,\n",
       "   0.41199,\n",
       "   0.41978,\n",
       "   0.42964,\n",
       "   0.44229,\n",
       "   0.42914,\n",
       "   0.43597,\n",
       "   0.42782,\n",
       "   0.44101,\n",
       "   0.43867,\n",
       "   0.44528,\n",
       "   0.45121,\n",
       "   0.44875,\n",
       "   0.44115,\n",
       "   0.45692,\n",
       "   0.47407,\n",
       "   0.46263,\n",
       "   0.47095,\n",
       "   0.4692,\n",
       "   0.46363,\n",
       "   0.47734,\n",
       "   0.46033,\n",
       "   0.46676,\n",
       "   0.47145,\n",
       "   0.4756,\n",
       "   0.49889,\n",
       "   0.48797,\n",
       "   0.4792,\n",
       "   0.50284,\n",
       "   0.47777,\n",
       "   0.49644,\n",
       "   0.49493,\n",
       "   0.4901,\n",
       "   0.48556,\n",
       "   0.48787,\n",
       "   0.50599,\n",
       "   0.50196,\n",
       "   0.4971,\n",
       "   0.4867,\n",
       "   0.50411,\n",
       "   0.51067,\n",
       "   0.51043,\n",
       "   0.50348,\n",
       "   0.52302,\n",
       "   0.51509,\n",
       "   0.5096,\n",
       "   0.51062,\n",
       "   0.51295,\n",
       "   0.51183,\n",
       "   0.50588,\n",
       "   0.50777,\n",
       "   0.51008,\n",
       "   0.5088,\n",
       "   0.51819,\n",
       "   0.51303,\n",
       "   0.52366,\n",
       "   0.51458,\n",
       "   0.52873,\n",
       "   0.51749,\n",
       "   0.5177,\n",
       "   0.51753,\n",
       "   0.52171,\n",
       "   0.53267,\n",
       "   0.52999,\n",
       "   0.5181,\n",
       "   0.52644,\n",
       "   0.52489,\n",
       "   0.52271,\n",
       "   0.51922,\n",
       "   0.52633,\n",
       "   0.54195,\n",
       "   0.53722,\n",
       "   0.53164,\n",
       "   0.52463,\n",
       "   0.53562,\n",
       "   0.5361,\n",
       "   0.53912,\n",
       "   0.53624,\n",
       "   0.54002,\n",
       "   0.53003,\n",
       "   0.53795,\n",
       "   0.53843,\n",
       "   0.5326,\n",
       "   0.52443,\n",
       "   0.5375,\n",
       "   0.54394,\n",
       "   0.54295,\n",
       "   0.54002,\n",
       "   0.54398,\n",
       "   0.53295,\n",
       "   0.53536,\n",
       "   0.54052,\n",
       "   0.53419,\n",
       "   0.5344,\n",
       "   0.544,\n",
       "   0.54247,\n",
       "   0.5372,\n",
       "   0.53574,\n",
       "   0.53939,\n",
       "   0.53734,\n",
       "   0.5373,\n",
       "   0.53961,\n",
       "   0.54106,\n",
       "   0.54391,\n",
       "   0.53672,\n",
       "   0.53933,\n",
       "   0.54289,\n",
       "   0.54717,\n",
       "   0.53742,\n",
       "   0.5378,\n",
       "   0.54848,\n",
       "   0.54319,\n",
       "   0.54767,\n",
       "   0.5541,\n",
       "   0.55832,\n",
       "   0.55352,\n",
       "   0.5494,\n",
       "   0.55026,\n",
       "   0.5483,\n",
       "   0.55248,\n",
       "   0.5486,\n",
       "   0.54473,\n",
       "   0.55326,\n",
       "   0.55247,\n",
       "   0.55725,\n",
       "   0.5568,\n",
       "   0.55482,\n",
       "   0.54676,\n",
       "   0.54839,\n",
       "   0.55154,\n",
       "   0.55104,\n",
       "   0.54919,\n",
       "   0.55104,\n",
       "   0.5506,\n",
       "   0.55153,\n",
       "   0.55304,\n",
       "   0.55319,\n",
       "   0.55129,\n",
       "   0.54773,\n",
       "   0.55051,\n",
       "   0.55358,\n",
       "   0.55585,\n",
       "   0.55602,\n",
       "   0.5542,\n",
       "   0.55799,\n",
       "   0.5572,\n",
       "   0.55531,\n",
       "   0.55258,\n",
       "   0.55124,\n",
       "   0.54781,\n",
       "   0.54935,\n",
       "   0.54921,\n",
       "   0.55065,\n",
       "   0.55086,\n",
       "   0.55412,\n",
       "   0.55486,\n",
       "   0.55345,\n",
       "   0.55389,\n",
       "   0.55312,\n",
       "   0.55342,\n",
       "   0.55352,\n",
       "   0.5541,\n",
       "   0.55201,\n",
       "   0.55278,\n",
       "   0.55246,\n",
       "   0.55317,\n",
       "   0.55306,\n",
       "   0.55618,\n",
       "   0.55782,\n",
       "   0.55512,\n",
       "   0.55316,\n",
       "   0.55458,\n",
       "   0.55516,\n",
       "   0.55466,\n",
       "   0.55429,\n",
       "   0.55328,\n",
       "   0.55475,\n",
       "   0.55505,\n",
       "   0.55455,\n",
       "   0.55468,\n",
       "   0.55185,\n",
       "   0.55185,\n",
       "   0.5542,\n",
       "   0.55573,\n",
       "   0.55564,\n",
       "   0.55611,\n",
       "   0.55531,\n",
       "   0.55847,\n",
       "   0.5577,\n",
       "   0.55708,\n",
       "   0.55843,\n",
       "   0.56283,\n",
       "   0.55998,\n",
       "   0.56099,\n",
       "   0.56233,\n",
       "   0.55989,\n",
       "   0.56322],\n",
       "  'metrics/mAP50-95(B)': [0.00023,\n",
       "   0.0011,\n",
       "   0.00268,\n",
       "   0.01598,\n",
       "   0.04491,\n",
       "   0.05226,\n",
       "   0.08326,\n",
       "   0.09129,\n",
       "   0.11605,\n",
       "   0.12564,\n",
       "   0.13329,\n",
       "   0.15081,\n",
       "   0.1589,\n",
       "   0.16545,\n",
       "   0.18263,\n",
       "   0.16595,\n",
       "   0.18711,\n",
       "   0.18994,\n",
       "   0.20118,\n",
       "   0.20235,\n",
       "   0.20137,\n",
       "   0.2241,\n",
       "   0.22608,\n",
       "   0.23679,\n",
       "   0.23952,\n",
       "   0.24552,\n",
       "   0.26186,\n",
       "   0.26126,\n",
       "   0.25078,\n",
       "   0.25751,\n",
       "   0.28625,\n",
       "   0.26863,\n",
       "   0.26204,\n",
       "   0.27456,\n",
       "   0.27058,\n",
       "   0.28272,\n",
       "   0.3049,\n",
       "   0.30316,\n",
       "   0.31376,\n",
       "   0.28498,\n",
       "   0.30802,\n",
       "   0.30754,\n",
       "   0.31207,\n",
       "   0.32255,\n",
       "   0.32856,\n",
       "   0.34031,\n",
       "   0.34013,\n",
       "   0.3299,\n",
       "   0.33965,\n",
       "   0.33507,\n",
       "   0.33657,\n",
       "   0.33525,\n",
       "   0.35083,\n",
       "   0.35324,\n",
       "   0.35424,\n",
       "   0.35377,\n",
       "   0.36137,\n",
       "   0.37385,\n",
       "   0.36579,\n",
       "   0.37005,\n",
       "   0.36899,\n",
       "   0.36286,\n",
       "   0.37525,\n",
       "   0.36339,\n",
       "   0.36717,\n",
       "   0.37847,\n",
       "   0.37828,\n",
       "   0.39528,\n",
       "   0.39077,\n",
       "   0.38718,\n",
       "   0.40194,\n",
       "   0.37952,\n",
       "   0.40218,\n",
       "   0.39707,\n",
       "   0.40198,\n",
       "   0.39601,\n",
       "   0.39206,\n",
       "   0.40866,\n",
       "   0.40322,\n",
       "   0.40564,\n",
       "   0.39663,\n",
       "   0.40476,\n",
       "   0.40656,\n",
       "   0.40724,\n",
       "   0.40626,\n",
       "   0.42217,\n",
       "   0.4187,\n",
       "   0.40997,\n",
       "   0.41249,\n",
       "   0.4173,\n",
       "   0.41481,\n",
       "   0.41146,\n",
       "   0.41636,\n",
       "   0.41163,\n",
       "   0.41612,\n",
       "   0.42425,\n",
       "   0.41919,\n",
       "   0.42341,\n",
       "   0.42381,\n",
       "   0.43379,\n",
       "   0.42186,\n",
       "   0.4176,\n",
       "   0.42296,\n",
       "   0.4307,\n",
       "   0.43996,\n",
       "   0.43259,\n",
       "   0.42672,\n",
       "   0.42838,\n",
       "   0.42835,\n",
       "   0.42531,\n",
       "   0.42165,\n",
       "   0.43178,\n",
       "   0.44176,\n",
       "   0.44121,\n",
       "   0.43607,\n",
       "   0.43362,\n",
       "   0.43789,\n",
       "   0.44381,\n",
       "   0.44748,\n",
       "   0.44151,\n",
       "   0.44343,\n",
       "   0.4381,\n",
       "   0.44388,\n",
       "   0.44677,\n",
       "   0.44756,\n",
       "   0.43666,\n",
       "   0.4469,\n",
       "   0.45113,\n",
       "   0.45041,\n",
       "   0.4464,\n",
       "   0.44966,\n",
       "   0.44308,\n",
       "   0.44615,\n",
       "   0.45352,\n",
       "   0.44633,\n",
       "   0.44722,\n",
       "   0.44971,\n",
       "   0.44997,\n",
       "   0.44893,\n",
       "   0.44909,\n",
       "   0.45083,\n",
       "   0.4491,\n",
       "   0.44601,\n",
       "   0.44314,\n",
       "   0.44833,\n",
       "   0.4504,\n",
       "   0.44443,\n",
       "   0.44736,\n",
       "   0.4498,\n",
       "   0.4539,\n",
       "   0.44962,\n",
       "   0.4455,\n",
       "   0.45444,\n",
       "   0.44866,\n",
       "   0.45461,\n",
       "   0.45766,\n",
       "   0.46274,\n",
       "   0.46068,\n",
       "   0.45631,\n",
       "   0.45611,\n",
       "   0.45561,\n",
       "   0.45615,\n",
       "   0.45383,\n",
       "   0.45243,\n",
       "   0.45962,\n",
       "   0.45734,\n",
       "   0.46072,\n",
       "   0.4591,\n",
       "   0.45993,\n",
       "   0.454,\n",
       "   0.45925,\n",
       "   0.46063,\n",
       "   0.46203,\n",
       "   0.46055,\n",
       "   0.45589,\n",
       "   0.45608,\n",
       "   0.45819,\n",
       "   0.45915,\n",
       "   0.45979,\n",
       "   0.45844,\n",
       "   0.45412,\n",
       "   0.4558,\n",
       "   0.45892,\n",
       "   0.45983,\n",
       "   0.45957,\n",
       "   0.45899,\n",
       "   0.45993,\n",
       "   0.45942,\n",
       "   0.45914,\n",
       "   0.45713,\n",
       "   0.46041,\n",
       "   0.45906,\n",
       "   0.46154,\n",
       "   0.46059,\n",
       "   0.45968,\n",
       "   0.46062,\n",
       "   0.46279,\n",
       "   0.46399,\n",
       "   0.46356,\n",
       "   0.46518,\n",
       "   0.46387,\n",
       "   0.4628,\n",
       "   0.46255,\n",
       "   0.46291,\n",
       "   0.46197,\n",
       "   0.46353,\n",
       "   0.46205,\n",
       "   0.46168,\n",
       "   0.46229,\n",
       "   0.46422,\n",
       "   0.46242,\n",
       "   0.46171,\n",
       "   0.46217,\n",
       "   0.46353,\n",
       "   0.46425,\n",
       "   0.46352,\n",
       "   0.46409,\n",
       "   0.46321,\n",
       "   0.46562,\n",
       "   0.46642,\n",
       "   0.46629,\n",
       "   0.46748,\n",
       "   0.46479,\n",
       "   0.46505,\n",
       "   0.46684,\n",
       "   0.46756,\n",
       "   0.46818,\n",
       "   0.46866,\n",
       "   0.46798,\n",
       "   0.46882,\n",
       "   0.46914,\n",
       "   0.46794,\n",
       "   0.46827,\n",
       "   0.47141,\n",
       "   0.46995,\n",
       "   0.47124,\n",
       "   0.47216,\n",
       "   0.47068,\n",
       "   0.47219],\n",
       "  'val/box_loss': [2.8577,\n",
       "   2.756,\n",
       "   2.2655,\n",
       "   1.8222,\n",
       "   1.6178,\n",
       "   1.4928,\n",
       "   1.3832,\n",
       "   1.3319,\n",
       "   1.2296,\n",
       "   1.2053,\n",
       "   1.1883,\n",
       "   1.1747,\n",
       "   1.1477,\n",
       "   1.1292,\n",
       "   1.0817,\n",
       "   1.0645,\n",
       "   1.055,\n",
       "   1.0128,\n",
       "   1.0354,\n",
       "   1.0137,\n",
       "   0.98468,\n",
       "   0.98182,\n",
       "   0.94991,\n",
       "   0.93924,\n",
       "   0.9422,\n",
       "   0.9318,\n",
       "   0.91393,\n",
       "   0.89419,\n",
       "   0.89924,\n",
       "   0.90356,\n",
       "   0.89236,\n",
       "   0.90411,\n",
       "   0.86718,\n",
       "   0.87376,\n",
       "   0.86686,\n",
       "   0.87106,\n",
       "   0.83995,\n",
       "   0.82492,\n",
       "   0.8341,\n",
       "   0.84739,\n",
       "   0.81382,\n",
       "   0.80817,\n",
       "   0.83134,\n",
       "   0.80593,\n",
       "   0.8242,\n",
       "   0.8051,\n",
       "   0.7819,\n",
       "   0.80471,\n",
       "   0.80419,\n",
       "   0.8167,\n",
       "   0.7946,\n",
       "   0.7801,\n",
       "   0.77177,\n",
       "   0.7787,\n",
       "   0.77301,\n",
       "   0.75878,\n",
       "   0.76854,\n",
       "   0.75618,\n",
       "   0.74867,\n",
       "   0.73727,\n",
       "   0.7563,\n",
       "   0.73606,\n",
       "   0.74316,\n",
       "   0.72923,\n",
       "   0.72878,\n",
       "   0.75028,\n",
       "   0.73028,\n",
       "   0.72805,\n",
       "   0.72329,\n",
       "   0.72375,\n",
       "   0.72319,\n",
       "   0.73488,\n",
       "   0.71543,\n",
       "   0.71817,\n",
       "   0.70738,\n",
       "   0.71314,\n",
       "   0.71177,\n",
       "   0.70693,\n",
       "   0.71749,\n",
       "   0.69734,\n",
       "   0.69443,\n",
       "   0.70695,\n",
       "   0.70936,\n",
       "   0.70712,\n",
       "   0.70499,\n",
       "   0.71709,\n",
       "   0.69653,\n",
       "   0.70116,\n",
       "   0.68305,\n",
       "   0.68273,\n",
       "   0.68898,\n",
       "   0.6837,\n",
       "   0.67945,\n",
       "   0.68129,\n",
       "   0.6797,\n",
       "   0.66733,\n",
       "   0.66181,\n",
       "   0.68061,\n",
       "   0.6733,\n",
       "   0.68013,\n",
       "   0.66719,\n",
       "   0.68729,\n",
       "   0.68266,\n",
       "   0.66822,\n",
       "   0.66013,\n",
       "   0.66732,\n",
       "   0.66421,\n",
       "   0.67395,\n",
       "   0.66329,\n",
       "   0.66499,\n",
       "   0.66584,\n",
       "   0.64936,\n",
       "   0.65455,\n",
       "   0.64624,\n",
       "   0.64895,\n",
       "   0.64222,\n",
       "   0.66047,\n",
       "   0.65485,\n",
       "   0.63993,\n",
       "   0.6432,\n",
       "   0.65644,\n",
       "   0.65796,\n",
       "   0.6517,\n",
       "   0.6525,\n",
       "   0.64407,\n",
       "   0.6473,\n",
       "   0.65011,\n",
       "   0.63845,\n",
       "   0.6367,\n",
       "   0.64593,\n",
       "   0.63851,\n",
       "   0.65024,\n",
       "   0.64585,\n",
       "   0.64325,\n",
       "   0.64889,\n",
       "   0.65265,\n",
       "   0.64249,\n",
       "   0.6454,\n",
       "   0.64676,\n",
       "   0.64558,\n",
       "   0.63252,\n",
       "   0.63425,\n",
       "   0.63152,\n",
       "   0.64418,\n",
       "   0.63773,\n",
       "   0.64267,\n",
       "   0.63828,\n",
       "   0.62854,\n",
       "   0.62486,\n",
       "   0.63103,\n",
       "   0.63017,\n",
       "   0.63684,\n",
       "   0.63749,\n",
       "   0.64121,\n",
       "   0.63825,\n",
       "   0.63293,\n",
       "   0.63998,\n",
       "   0.63714,\n",
       "   0.63971,\n",
       "   0.6386,\n",
       "   0.63508,\n",
       "   0.63629,\n",
       "   0.63303,\n",
       "   0.63523,\n",
       "   0.63433,\n",
       "   0.63134,\n",
       "   0.631,\n",
       "   0.62977,\n",
       "   0.63116,\n",
       "   0.63226,\n",
       "   0.62893,\n",
       "   0.62694,\n",
       "   0.62369,\n",
       "   0.62718,\n",
       "   0.62918,\n",
       "   0.62828,\n",
       "   0.62888,\n",
       "   0.62423,\n",
       "   0.62615,\n",
       "   0.62901,\n",
       "   0.62917,\n",
       "   0.62879,\n",
       "   0.63093,\n",
       "   0.63096,\n",
       "   0.62679,\n",
       "   0.62518,\n",
       "   0.62533,\n",
       "   0.62739,\n",
       "   0.62533,\n",
       "   0.62326,\n",
       "   0.62056,\n",
       "   0.61694,\n",
       "   0.61817,\n",
       "   0.61491,\n",
       "   0.61829,\n",
       "   0.61875,\n",
       "   0.61648,\n",
       "   0.61641,\n",
       "   0.61555,\n",
       "   0.61492,\n",
       "   0.61777,\n",
       "   0.61952,\n",
       "   0.61673,\n",
       "   0.61468,\n",
       "   0.61236,\n",
       "   0.613,\n",
       "   0.61259,\n",
       "   0.61105,\n",
       "   0.61228,\n",
       "   0.61331,\n",
       "   0.61417,\n",
       "   0.61541,\n",
       "   0.61533,\n",
       "   0.61372,\n",
       "   0.61217,\n",
       "   0.60962,\n",
       "   0.60652,\n",
       "   0.60631,\n",
       "   0.60645,\n",
       "   0.60463,\n",
       "   0.60487,\n",
       "   0.60447,\n",
       "   0.60644,\n",
       "   0.60598,\n",
       "   0.60709,\n",
       "   0.60774,\n",
       "   0.60772,\n",
       "   0.60934,\n",
       "   0.61017,\n",
       "   0.60884,\n",
       "   0.60904,\n",
       "   0.60947,\n",
       "   0.60886,\n",
       "   0.60707,\n",
       "   0.60706,\n",
       "   0.60817,\n",
       "   0.60827,\n",
       "   0.61006,\n",
       "   0.61076],\n",
       "  'val/cls_loss': [4.646,\n",
       "   5.2125,\n",
       "   4.2777,\n",
       "   3.8579,\n",
       "   3.4438,\n",
       "   3.3946,\n",
       "   3.0058,\n",
       "   2.9261,\n",
       "   2.792,\n",
       "   2.7537,\n",
       "   2.6582,\n",
       "   2.6113,\n",
       "   2.5376,\n",
       "   2.5375,\n",
       "   2.4392,\n",
       "   2.4079,\n",
       "   2.3879,\n",
       "   2.3636,\n",
       "   2.3067,\n",
       "   2.2776,\n",
       "   2.277,\n",
       "   2.1546,\n",
       "   2.1576,\n",
       "   2.0873,\n",
       "   2.0655,\n",
       "   2.0852,\n",
       "   1.9721,\n",
       "   2.0172,\n",
       "   2.0099,\n",
       "   2.0442,\n",
       "   1.8962,\n",
       "   1.972,\n",
       "   1.9627,\n",
       "   1.9436,\n",
       "   1.8843,\n",
       "   1.8926,\n",
       "   1.7821,\n",
       "   1.784,\n",
       "   1.776,\n",
       "   1.9217,\n",
       "   1.7363,\n",
       "   1.7501,\n",
       "   1.7483,\n",
       "   1.7695,\n",
       "   1.7686,\n",
       "   1.6569,\n",
       "   1.6311,\n",
       "   1.6592,\n",
       "   1.6802,\n",
       "   1.6921,\n",
       "   1.6804,\n",
       "   1.6569,\n",
       "   1.6122,\n",
       "   1.6527,\n",
       "   1.6018,\n",
       "   1.6044,\n",
       "   1.5658,\n",
       "   1.5539,\n",
       "   1.547,\n",
       "   1.5681,\n",
       "   1.5353,\n",
       "   1.5302,\n",
       "   1.5099,\n",
       "   1.5373,\n",
       "   1.5194,\n",
       "   1.485,\n",
       "   1.4645,\n",
       "   1.4718,\n",
       "   1.4373,\n",
       "   1.4777,\n",
       "   1.4659,\n",
       "   1.4635,\n",
       "   1.4511,\n",
       "   1.4522,\n",
       "   1.4544,\n",
       "   1.4195,\n",
       "   1.4439,\n",
       "   1.4185,\n",
       "   1.3929,\n",
       "   1.3977,\n",
       "   1.4148,\n",
       "   1.414,\n",
       "   1.3979,\n",
       "   1.3931,\n",
       "   1.4352,\n",
       "   1.397,\n",
       "   1.3979,\n",
       "   1.3875,\n",
       "   1.3872,\n",
       "   1.3499,\n",
       "   1.3536,\n",
       "   1.3621,\n",
       "   1.3658,\n",
       "   1.3677,\n",
       "   1.3288,\n",
       "   1.3091,\n",
       "   1.3143,\n",
       "   1.3332,\n",
       "   1.3484,\n",
       "   1.338,\n",
       "   1.3323,\n",
       "   1.3333,\n",
       "   1.3097,\n",
       "   1.2876,\n",
       "   1.2753,\n",
       "   1.2909,\n",
       "   1.3454,\n",
       "   1.3133,\n",
       "   1.3086,\n",
       "   1.3112,\n",
       "   1.3061,\n",
       "   1.2984,\n",
       "   1.2868,\n",
       "   1.3068,\n",
       "   1.3133,\n",
       "   1.3082,\n",
       "   1.3197,\n",
       "   1.3191,\n",
       "   1.2923,\n",
       "   1.2874,\n",
       "   1.2836,\n",
       "   1.3048,\n",
       "   1.2888,\n",
       "   1.2824,\n",
       "   1.306,\n",
       "   1.2951,\n",
       "   1.2974,\n",
       "   1.2977,\n",
       "   1.2766,\n",
       "   1.2977,\n",
       "   1.281,\n",
       "   1.3034,\n",
       "   1.294,\n",
       "   1.2781,\n",
       "   1.3037,\n",
       "   1.2806,\n",
       "   1.2683,\n",
       "   1.2797,\n",
       "   1.2949,\n",
       "   1.2799,\n",
       "   1.2814,\n",
       "   1.2852,\n",
       "   1.2839,\n",
       "   1.2957,\n",
       "   1.2743,\n",
       "   1.2729,\n",
       "   1.2842,\n",
       "   1.281,\n",
       "   1.2719,\n",
       "   1.2823,\n",
       "   1.2954,\n",
       "   1.2912,\n",
       "   1.2873,\n",
       "   1.2793,\n",
       "   1.2675,\n",
       "   1.2675,\n",
       "   1.2677,\n",
       "   1.2503,\n",
       "   1.27,\n",
       "   1.2715,\n",
       "   1.2684,\n",
       "   1.2601,\n",
       "   1.2616,\n",
       "   1.2601,\n",
       "   1.267,\n",
       "   1.2569,\n",
       "   1.2574,\n",
       "   1.2512,\n",
       "   1.2534,\n",
       "   1.2531,\n",
       "   1.256,\n",
       "   1.2468,\n",
       "   1.2415,\n",
       "   1.2503,\n",
       "   1.2528,\n",
       "   1.262,\n",
       "   1.255,\n",
       "   1.2476,\n",
       "   1.2476,\n",
       "   1.2451,\n",
       "   1.2503,\n",
       "   1.2553,\n",
       "   1.2474,\n",
       "   1.2428,\n",
       "   1.2493,\n",
       "   1.2552,\n",
       "   1.2589,\n",
       "   1.2693,\n",
       "   1.2689,\n",
       "   1.2672,\n",
       "   1.2559,\n",
       "   1.2515,\n",
       "   1.2554,\n",
       "   1.2537,\n",
       "   1.2553,\n",
       "   1.2536,\n",
       "   1.2475,\n",
       "   1.2438,\n",
       "   1.2521,\n",
       "   1.2463,\n",
       "   1.2512,\n",
       "   1.2455,\n",
       "   1.2469,\n",
       "   1.2485,\n",
       "   1.2478,\n",
       "   1.2517,\n",
       "   1.2501,\n",
       "   1.2484,\n",
       "   1.2492,\n",
       "   1.2498,\n",
       "   1.2482,\n",
       "   1.2495,\n",
       "   1.2444,\n",
       "   1.2501,\n",
       "   1.2542,\n",
       "   1.248,\n",
       "   1.2481,\n",
       "   1.247,\n",
       "   1.2483,\n",
       "   1.2514,\n",
       "   1.2559,\n",
       "   1.2535,\n",
       "   1.2583,\n",
       "   1.2596,\n",
       "   1.26,\n",
       "   1.2571,\n",
       "   1.2636,\n",
       "   1.2658,\n",
       "   1.266,\n",
       "   1.2675,\n",
       "   1.2662,\n",
       "   1.2648,\n",
       "   1.2635,\n",
       "   1.2621,\n",
       "   1.2632,\n",
       "   1.2587,\n",
       "   1.2637,\n",
       "   1.2647,\n",
       "   1.2656],\n",
       "  'val/dfl_loss': [3.787,\n",
       "   3.3021,\n",
       "   2.9256,\n",
       "   2.4862,\n",
       "   2.2189,\n",
       "   2.0963,\n",
       "   1.9362,\n",
       "   1.8876,\n",
       "   1.791,\n",
       "   1.7559,\n",
       "   1.7245,\n",
       "   1.7124,\n",
       "   1.6666,\n",
       "   1.6744,\n",
       "   1.6264,\n",
       "   1.6178,\n",
       "   1.5825,\n",
       "   1.5641,\n",
       "   1.5522,\n",
       "   1.54,\n",
       "   1.5238,\n",
       "   1.4845,\n",
       "   1.4597,\n",
       "   1.4652,\n",
       "   1.4571,\n",
       "   1.4602,\n",
       "   1.4297,\n",
       "   1.4251,\n",
       "   1.4233,\n",
       "   1.4349,\n",
       "   1.4084,\n",
       "   1.4168,\n",
       "   1.3826,\n",
       "   1.3874,\n",
       "   1.3827,\n",
       "   1.4045,\n",
       "   1.3743,\n",
       "   1.3475,\n",
       "   1.3617,\n",
       "   1.3819,\n",
       "   1.342,\n",
       "   1.3332,\n",
       "   1.3647,\n",
       "   1.3311,\n",
       "   1.3397,\n",
       "   1.3383,\n",
       "   1.3055,\n",
       "   1.332,\n",
       "   1.3369,\n",
       "   1.336,\n",
       "   1.3193,\n",
       "   1.304,\n",
       "   1.2994,\n",
       "   1.3067,\n",
       "   1.3047,\n",
       "   1.293,\n",
       "   1.2871,\n",
       "   1.2855,\n",
       "   1.2802,\n",
       "   1.2569,\n",
       "   1.2655,\n",
       "   1.2649,\n",
       "   1.2673,\n",
       "   1.2627,\n",
       "   1.2613,\n",
       "   1.2681,\n",
       "   1.2564,\n",
       "   1.2515,\n",
       "   1.2522,\n",
       "   1.254,\n",
       "   1.2606,\n",
       "   1.2666,\n",
       "   1.2515,\n",
       "   1.2533,\n",
       "   1.236,\n",
       "   1.2379,\n",
       "   1.2445,\n",
       "   1.2437,\n",
       "   1.2491,\n",
       "   1.2357,\n",
       "   1.2293,\n",
       "   1.2378,\n",
       "   1.2439,\n",
       "   1.2305,\n",
       "   1.2298,\n",
       "   1.2532,\n",
       "   1.2203,\n",
       "   1.2245,\n",
       "   1.2186,\n",
       "   1.2189,\n",
       "   1.225,\n",
       "   1.213,\n",
       "   1.209,\n",
       "   1.2174,\n",
       "   1.2127,\n",
       "   1.1951,\n",
       "   1.2018,\n",
       "   1.2185,\n",
       "   1.2157,\n",
       "   1.2204,\n",
       "   1.1982,\n",
       "   1.227,\n",
       "   1.2246,\n",
       "   1.2142,\n",
       "   1.2061,\n",
       "   1.2012,\n",
       "   1.2032,\n",
       "   1.2015,\n",
       "   1.1948,\n",
       "   1.2021,\n",
       "   1.2033,\n",
       "   1.176,\n",
       "   1.1891,\n",
       "   1.1766,\n",
       "   1.193,\n",
       "   1.1782,\n",
       "   1.201,\n",
       "   1.1933,\n",
       "   1.1812,\n",
       "   1.1887,\n",
       "   1.2065,\n",
       "   1.2031,\n",
       "   1.2006,\n",
       "   1.198,\n",
       "   1.1917,\n",
       "   1.202,\n",
       "   1.1998,\n",
       "   1.1874,\n",
       "   1.1839,\n",
       "   1.1908,\n",
       "   1.1896,\n",
       "   1.1974,\n",
       "   1.1904,\n",
       "   1.185,\n",
       "   1.1918,\n",
       "   1.2074,\n",
       "   1.1904,\n",
       "   1.1924,\n",
       "   1.1952,\n",
       "   1.1874,\n",
       "   1.1719,\n",
       "   1.1721,\n",
       "   1.1708,\n",
       "   1.1827,\n",
       "   1.1823,\n",
       "   1.1896,\n",
       "   1.1815,\n",
       "   1.1746,\n",
       "   1.1674,\n",
       "   1.1746,\n",
       "   1.1768,\n",
       "   1.1803,\n",
       "   1.1764,\n",
       "   1.1869,\n",
       "   1.1825,\n",
       "   1.1777,\n",
       "   1.1839,\n",
       "   1.1749,\n",
       "   1.1759,\n",
       "   1.1744,\n",
       "   1.1677,\n",
       "   1.1694,\n",
       "   1.1698,\n",
       "   1.1727,\n",
       "   1.1719,\n",
       "   1.1698,\n",
       "   1.1714,\n",
       "   1.1702,\n",
       "   1.1711,\n",
       "   1.1764,\n",
       "   1.1711,\n",
       "   1.172,\n",
       "   1.1716,\n",
       "   1.1739,\n",
       "   1.1755,\n",
       "   1.1716,\n",
       "   1.1711,\n",
       "   1.1657,\n",
       "   1.1681,\n",
       "   1.1712,\n",
       "   1.1709,\n",
       "   1.1691,\n",
       "   1.1728,\n",
       "   1.1718,\n",
       "   1.1682,\n",
       "   1.1664,\n",
       "   1.1671,\n",
       "   1.1706,\n",
       "   1.1661,\n",
       "   1.1691,\n",
       "   1.1696,\n",
       "   1.1675,\n",
       "   1.1688,\n",
       "   1.165,\n",
       "   1.1688,\n",
       "   1.1716,\n",
       "   1.1709,\n",
       "   1.1707,\n",
       "   1.1693,\n",
       "   1.1701,\n",
       "   1.1718,\n",
       "   1.1732,\n",
       "   1.1716,\n",
       "   1.1696,\n",
       "   1.1679,\n",
       "   1.1668,\n",
       "   1.1663,\n",
       "   1.1657,\n",
       "   1.1676,\n",
       "   1.1681,\n",
       "   1.168,\n",
       "   1.1705,\n",
       "   1.1697,\n",
       "   1.1686,\n",
       "   1.1672,\n",
       "   1.1647,\n",
       "   1.1619,\n",
       "   1.1613,\n",
       "   1.1614,\n",
       "   1.16,\n",
       "   1.1606,\n",
       "   1.1595,\n",
       "   1.1613,\n",
       "   1.1619,\n",
       "   1.1633,\n",
       "   1.1639,\n",
       "   1.1645,\n",
       "   1.1658,\n",
       "   1.1661,\n",
       "   1.1647,\n",
       "   1.1651,\n",
       "   1.1654,\n",
       "   1.1655,\n",
       "   1.1643,\n",
       "   1.1642,\n",
       "   1.1644,\n",
       "   1.1642,\n",
       "   1.166,\n",
       "   1.1666],\n",
       "  'lr/pg0': [0.070128,\n",
       "   0.040106,\n",
       "   0.010062,\n",
       "   0.009901,\n",
       "   0.009901,\n",
       "   0.009868,\n",
       "   0.009835,\n",
       "   0.009802,\n",
       "   0.009769,\n",
       "   0.009736,\n",
       "   0.009703,\n",
       "   0.00967,\n",
       "   0.009637,\n",
       "   0.009604,\n",
       "   0.009571,\n",
       "   0.009538,\n",
       "   0.009505,\n",
       "   0.009472,\n",
       "   0.009439,\n",
       "   0.009406,\n",
       "   0.009373,\n",
       "   0.00934,\n",
       "   0.009307,\n",
       "   0.009274,\n",
       "   0.009241,\n",
       "   0.009208,\n",
       "   0.009175,\n",
       "   0.009142,\n",
       "   0.009109,\n",
       "   0.009076,\n",
       "   0.009043,\n",
       "   0.00901,\n",
       "   0.008977,\n",
       "   0.008944,\n",
       "   0.008911,\n",
       "   0.008878,\n",
       "   0.008845,\n",
       "   0.008812,\n",
       "   0.008779,\n",
       "   0.008746,\n",
       "   0.008713,\n",
       "   0.00868,\n",
       "   0.008647,\n",
       "   0.008614,\n",
       "   0.008581,\n",
       "   0.008548,\n",
       "   0.008515,\n",
       "   0.008482,\n",
       "   0.008449,\n",
       "   0.008416,\n",
       "   0.008383,\n",
       "   0.00835,\n",
       "   0.008317,\n",
       "   0.008284,\n",
       "   0.008251,\n",
       "   0.008218,\n",
       "   0.008185,\n",
       "   0.008152,\n",
       "   0.008119,\n",
       "   0.008086,\n",
       "   0.008053,\n",
       "   0.00802,\n",
       "   0.007987,\n",
       "   0.007954,\n",
       "   0.007921,\n",
       "   0.007888,\n",
       "   0.007855,\n",
       "   0.007822,\n",
       "   0.007789,\n",
       "   0.007756,\n",
       "   0.007723,\n",
       "   0.00769,\n",
       "   0.007657,\n",
       "   0.007624,\n",
       "   0.007591,\n",
       "   0.007558,\n",
       "   0.007525,\n",
       "   0.007492,\n",
       "   0.007459,\n",
       "   0.007426,\n",
       "   0.007393,\n",
       "   0.00736,\n",
       "   0.007327,\n",
       "   0.007294,\n",
       "   0.007261,\n",
       "   0.007228,\n",
       "   0.007195,\n",
       "   0.007162,\n",
       "   0.007129,\n",
       "   0.007096,\n",
       "   0.007063,\n",
       "   0.00703,\n",
       "   0.006997,\n",
       "   0.006964,\n",
       "   0.006931,\n",
       "   0.006898,\n",
       "   0.006865,\n",
       "   0.006832,\n",
       "   0.006799,\n",
       "   0.006766,\n",
       "   0.006733,\n",
       "   0.0067,\n",
       "   0.006667,\n",
       "   0.006634,\n",
       "   0.006601,\n",
       "   0.006568,\n",
       "   0.006535,\n",
       "   0.006502,\n",
       "   0.006469,\n",
       "   0.006436,\n",
       "   0.006403,\n",
       "   0.00637,\n",
       "   0.006337,\n",
       "   0.006304,\n",
       "   0.006271,\n",
       "   0.006238,\n",
       "   0.006205,\n",
       "   0.006172,\n",
       "   0.006139,\n",
       "   0.006106,\n",
       "   0.006073,\n",
       "   0.00604,\n",
       "   0.006007,\n",
       "   0.005974,\n",
       "   0.005941,\n",
       "   0.005908,\n",
       "   0.005875,\n",
       "   0.005842,\n",
       "   0.005809,\n",
       "   0.005776,\n",
       "   0.005743,\n",
       "   0.00571,\n",
       "   0.005677,\n",
       "   0.005644,\n",
       "   0.005611,\n",
       "   0.005578,\n",
       "   0.005545,\n",
       "   0.005512,\n",
       "   0.005479,\n",
       "   0.005446,\n",
       "   0.005413,\n",
       "   0.00538,\n",
       "   0.005347,\n",
       "   0.005314,\n",
       "   0.005281,\n",
       "   0.005248,\n",
       "   0.005215,\n",
       "   0.005182,\n",
       "   0.005149,\n",
       "   0.005116,\n",
       "   0.005083,\n",
       "   0.00505,\n",
       "   0.005017,\n",
       "   0.004984,\n",
       "   0.004951,\n",
       "   0.004918,\n",
       "   0.004885,\n",
       "   0.004852,\n",
       "   0.004819,\n",
       "   0.004786,\n",
       "   0.004753,\n",
       "   0.00472,\n",
       "   0.004687,\n",
       "   0.004654,\n",
       "   0.004621,\n",
       "   0.004588,\n",
       "   0.004555,\n",
       "   0.004522,\n",
       "   0.004489,\n",
       "   0.004456,\n",
       "   0.004423,\n",
       "   0.00439,\n",
       "   0.004357,\n",
       "   0.004324,\n",
       "   0.004291,\n",
       "   0.004258,\n",
       "   0.004225,\n",
       "   0.004192,\n",
       "   0.004159,\n",
       "   0.004126,\n",
       "   0.004093,\n",
       "   0.00406,\n",
       "   0.004027,\n",
       "   0.003994,\n",
       "   0.003961,\n",
       "   0.003928,\n",
       "   0.003895,\n",
       "   0.003862,\n",
       "   0.003829,\n",
       "   0.003796,\n",
       "   0.003763,\n",
       "   0.00373,\n",
       "   0.003697,\n",
       "   0.003664,\n",
       "   0.003631,\n",
       "   0.003598,\n",
       "   0.003565,\n",
       "   0.003532,\n",
       "   0.003499,\n",
       "   0.003466,\n",
       "   0.003433,\n",
       "   0.0034,\n",
       "   0.003367,\n",
       "   0.003334,\n",
       "   0.003301,\n",
       "   0.003268,\n",
       "   0.003235,\n",
       "   0.003202,\n",
       "   0.003169,\n",
       "   0.003136,\n",
       "   0.003103,\n",
       "   0.00307,\n",
       "   0.003037,\n",
       "   0.003004,\n",
       "   0.002971,\n",
       "   0.002938,\n",
       "   0.002905,\n",
       "   0.002872,\n",
       "   0.002839,\n",
       "   0.002806,\n",
       "   0.002773,\n",
       "   0.00274,\n",
       "   0.002707,\n",
       "   0.002674,\n",
       "   0.002641,\n",
       "   0.002608,\n",
       "   0.002575,\n",
       "   0.002542,\n",
       "   0.002509,\n",
       "   0.002476,\n",
       "   0.002443,\n",
       "   0.00241,\n",
       "   0.002377,\n",
       "   0.002344,\n",
       "   0.002311,\n",
       "   0.002278,\n",
       "   0.002245,\n",
       "   0.002212,\n",
       "   0.002179],\n",
       "  'lr/pg1': [0.0033191,\n",
       "   0.0066305,\n",
       "   0.0099199,\n",
       "   0.009901,\n",
       "   0.009901,\n",
       "   0.009868,\n",
       "   0.009835,\n",
       "   0.009802,\n",
       "   0.009769,\n",
       "   0.009736,\n",
       "   0.009703,\n",
       "   0.00967,\n",
       "   0.009637,\n",
       "   0.009604,\n",
       "   0.009571,\n",
       "   0.009538,\n",
       "   0.009505,\n",
       "   0.009472,\n",
       "   0.009439,\n",
       "   0.009406,\n",
       "   0.009373,\n",
       "   0.00934,\n",
       "   0.009307,\n",
       "   0.009274,\n",
       "   0.009241,\n",
       "   0.009208,\n",
       "   0.009175,\n",
       "   0.009142,\n",
       "   0.009109,\n",
       "   0.009076,\n",
       "   0.009043,\n",
       "   0.00901,\n",
       "   0.008977,\n",
       "   0.008944,\n",
       "   0.008911,\n",
       "   0.008878,\n",
       "   0.008845,\n",
       "   0.008812,\n",
       "   0.008779,\n",
       "   0.008746,\n",
       "   0.008713,\n",
       "   0.00868,\n",
       "   0.008647,\n",
       "   0.008614,\n",
       "   0.008581,\n",
       "   0.008548,\n",
       "   0.008515,\n",
       "   0.008482,\n",
       "   0.008449,\n",
       "   0.008416,\n",
       "   0.008383,\n",
       "   0.00835,\n",
       "   0.008317,\n",
       "   0.008284,\n",
       "   0.008251,\n",
       "   0.008218,\n",
       "   0.008185,\n",
       "   0.008152,\n",
       "   0.008119,\n",
       "   0.008086,\n",
       "   0.008053,\n",
       "   0.00802,\n",
       "   0.007987,\n",
       "   0.007954,\n",
       "   0.007921,\n",
       "   0.007888,\n",
       "   0.007855,\n",
       "   0.007822,\n",
       "   0.007789,\n",
       "   0.007756,\n",
       "   0.007723,\n",
       "   0.00769,\n",
       "   0.007657,\n",
       "   0.007624,\n",
       "   0.007591,\n",
       "   0.007558,\n",
       "   0.007525,\n",
       "   0.007492,\n",
       "   0.007459,\n",
       "   0.007426,\n",
       "   0.007393,\n",
       "   0.00736,\n",
       "   0.007327,\n",
       "   0.007294,\n",
       "   0.007261,\n",
       "   0.007228,\n",
       "   0.007195,\n",
       "   0.007162,\n",
       "   0.007129,\n",
       "   0.007096,\n",
       "   0.007063,\n",
       "   0.00703,\n",
       "   0.006997,\n",
       "   0.006964,\n",
       "   0.006931,\n",
       "   0.006898,\n",
       "   0.006865,\n",
       "   0.006832,\n",
       "   0.006799,\n",
       "   0.006766,\n",
       "   0.006733,\n",
       "   0.0067,\n",
       "   0.006667,\n",
       "   0.006634,\n",
       "   0.006601,\n",
       "   0.006568,\n",
       "   0.006535,\n",
       "   0.006502,\n",
       "   0.006469,\n",
       "   0.006436,\n",
       "   0.006403,\n",
       "   0.00637,\n",
       "   0.006337,\n",
       "   0.006304,\n",
       "   0.006271,\n",
       "   0.006238,\n",
       "   0.006205,\n",
       "   0.006172,\n",
       "   0.006139,\n",
       "   0.006106,\n",
       "   0.006073,\n",
       "   0.00604,\n",
       "   0.006007,\n",
       "   0.005974,\n",
       "   0.005941,\n",
       "   0.005908,\n",
       "   0.005875,\n",
       "   0.005842,\n",
       "   0.005809,\n",
       "   0.005776,\n",
       "   0.005743,\n",
       "   0.00571,\n",
       "   0.005677,\n",
       "   0.005644,\n",
       "   0.005611,\n",
       "   0.005578,\n",
       "   0.005545,\n",
       "   0.005512,\n",
       "   0.005479,\n",
       "   0.005446,\n",
       "   0.005413,\n",
       "   0.00538,\n",
       "   0.005347,\n",
       "   0.005314,\n",
       "   0.005281,\n",
       "   0.005248,\n",
       "   0.005215,\n",
       "   0.005182,\n",
       "   0.005149,\n",
       "   0.005116,\n",
       "   0.005083,\n",
       "   0.00505,\n",
       "   0.005017,\n",
       "   0.004984,\n",
       "   0.004951,\n",
       "   0.004918,\n",
       "   0.004885,\n",
       "   0.004852,\n",
       "   0.004819,\n",
       "   0.004786,\n",
       "   0.004753,\n",
       "   0.00472,\n",
       "   0.004687,\n",
       "   0.004654,\n",
       "   0.004621,\n",
       "   0.004588,\n",
       "   0.004555,\n",
       "   0.004522,\n",
       "   0.004489,\n",
       "   0.004456,\n",
       "   0.004423,\n",
       "   0.00439,\n",
       "   0.004357,\n",
       "   0.004324,\n",
       "   0.004291,\n",
       "   0.004258,\n",
       "   0.004225,\n",
       "   0.004192,\n",
       "   0.004159,\n",
       "   0.004126,\n",
       "   0.004093,\n",
       "   0.00406,\n",
       "   0.004027,\n",
       "   0.003994,\n",
       "   0.003961,\n",
       "   0.003928,\n",
       "   0.003895,\n",
       "   0.003862,\n",
       "   0.003829,\n",
       "   0.003796,\n",
       "   0.003763,\n",
       "   0.00373,\n",
       "   0.003697,\n",
       "   0.003664,\n",
       "   0.003631,\n",
       "   0.003598,\n",
       "   0.003565,\n",
       "   0.003532,\n",
       "   0.003499,\n",
       "   0.003466,\n",
       "   0.003433,\n",
       "   0.0034,\n",
       "   0.003367,\n",
       "   0.003334,\n",
       "   0.003301,\n",
       "   0.003268,\n",
       "   0.003235,\n",
       "   0.003202,\n",
       "   0.003169,\n",
       "   0.003136,\n",
       "   0.003103,\n",
       "   0.00307,\n",
       "   0.003037,\n",
       "   0.003004,\n",
       "   0.002971,\n",
       "   0.002938,\n",
       "   0.002905,\n",
       "   0.002872,\n",
       "   0.002839,\n",
       "   0.002806,\n",
       "   0.002773,\n",
       "   0.00274,\n",
       "   0.002707,\n",
       "   0.002674,\n",
       "   0.002641,\n",
       "   0.002608,\n",
       "   0.002575,\n",
       "   0.002542,\n",
       "   0.002509,\n",
       "   0.002476,\n",
       "   0.002443,\n",
       "   0.00241,\n",
       "   0.002377,\n",
       "   0.002344,\n",
       "   0.002311,\n",
       "   0.002278,\n",
       "   0.002245,\n",
       "   0.002212,\n",
       "   0.002179],\n",
       "  'lr/pg2': [0.0033191,\n",
       "   0.0066305,\n",
       "   0.0099199,\n",
       "   0.009901,\n",
       "   0.009901,\n",
       "   0.009868,\n",
       "   0.009835,\n",
       "   0.009802,\n",
       "   0.009769,\n",
       "   0.009736,\n",
       "   0.009703,\n",
       "   0.00967,\n",
       "   0.009637,\n",
       "   0.009604,\n",
       "   0.009571,\n",
       "   0.009538,\n",
       "   0.009505,\n",
       "   0.009472,\n",
       "   0.009439,\n",
       "   0.009406,\n",
       "   0.009373,\n",
       "   0.00934,\n",
       "   0.009307,\n",
       "   0.009274,\n",
       "   0.009241,\n",
       "   0.009208,\n",
       "   0.009175,\n",
       "   0.009142,\n",
       "   0.009109,\n",
       "   0.009076,\n",
       "   0.009043,\n",
       "   0.00901,\n",
       "   0.008977,\n",
       "   0.008944,\n",
       "   0.008911,\n",
       "   0.008878,\n",
       "   0.008845,\n",
       "   0.008812,\n",
       "   0.008779,\n",
       "   0.008746,\n",
       "   0.008713,\n",
       "   0.00868,\n",
       "   0.008647,\n",
       "   0.008614,\n",
       "   0.008581,\n",
       "   0.008548,\n",
       "   0.008515,\n",
       "   0.008482,\n",
       "   0.008449,\n",
       "   0.008416,\n",
       "   0.008383,\n",
       "   0.00835,\n",
       "   0.008317,\n",
       "   0.008284,\n",
       "   0.008251,\n",
       "   0.008218,\n",
       "   0.008185,\n",
       "   0.008152,\n",
       "   0.008119,\n",
       "   0.008086,\n",
       "   0.008053,\n",
       "   0.00802,\n",
       "   0.007987,\n",
       "   0.007954,\n",
       "   0.007921,\n",
       "   0.007888,\n",
       "   0.007855,\n",
       "   0.007822,\n",
       "   0.007789,\n",
       "   0.007756,\n",
       "   0.007723,\n",
       "   0.00769,\n",
       "   0.007657,\n",
       "   0.007624,\n",
       "   0.007591,\n",
       "   0.007558,\n",
       "   0.007525,\n",
       "   0.007492,\n",
       "   0.007459,\n",
       "   0.007426,\n",
       "   0.007393,\n",
       "   0.00736,\n",
       "   0.007327,\n",
       "   0.007294,\n",
       "   0.007261,\n",
       "   0.007228,\n",
       "   0.007195,\n",
       "   0.007162,\n",
       "   0.007129,\n",
       "   0.007096,\n",
       "   0.007063,\n",
       "   0.00703,\n",
       "   0.006997,\n",
       "   0.006964,\n",
       "   0.006931,\n",
       "   0.006898,\n",
       "   0.006865,\n",
       "   0.006832,\n",
       "   0.006799,\n",
       "   0.006766,\n",
       "   0.006733,\n",
       "   0.0067,\n",
       "   0.006667,\n",
       "   0.006634,\n",
       "   0.006601,\n",
       "   0.006568,\n",
       "   0.006535,\n",
       "   0.006502,\n",
       "   0.006469,\n",
       "   0.006436,\n",
       "   0.006403,\n",
       "   0.00637,\n",
       "   0.006337,\n",
       "   0.006304,\n",
       "   0.006271,\n",
       "   0.006238,\n",
       "   0.006205,\n",
       "   0.006172,\n",
       "   0.006139,\n",
       "   0.006106,\n",
       "   0.006073,\n",
       "   0.00604,\n",
       "   0.006007,\n",
       "   0.005974,\n",
       "   0.005941,\n",
       "   0.005908,\n",
       "   0.005875,\n",
       "   0.005842,\n",
       "   0.005809,\n",
       "   0.005776,\n",
       "   0.005743,\n",
       "   0.00571,\n",
       "   0.005677,\n",
       "   0.005644,\n",
       "   0.005611,\n",
       "   0.005578,\n",
       "   0.005545,\n",
       "   0.005512,\n",
       "   0.005479,\n",
       "   0.005446,\n",
       "   0.005413,\n",
       "   0.00538,\n",
       "   0.005347,\n",
       "   0.005314,\n",
       "   0.005281,\n",
       "   0.005248,\n",
       "   0.005215,\n",
       "   0.005182,\n",
       "   0.005149,\n",
       "   0.005116,\n",
       "   0.005083,\n",
       "   0.00505,\n",
       "   0.005017,\n",
       "   0.004984,\n",
       "   0.004951,\n",
       "   0.004918,\n",
       "   0.004885,\n",
       "   0.004852,\n",
       "   0.004819,\n",
       "   0.004786,\n",
       "   0.004753,\n",
       "   0.00472,\n",
       "   0.004687,\n",
       "   0.004654,\n",
       "   0.004621,\n",
       "   0.004588,\n",
       "   0.004555,\n",
       "   0.004522,\n",
       "   0.004489,\n",
       "   0.004456,\n",
       "   0.004423,\n",
       "   0.00439,\n",
       "   0.004357,\n",
       "   0.004324,\n",
       "   0.004291,\n",
       "   0.004258,\n",
       "   0.004225,\n",
       "   0.004192,\n",
       "   0.004159,\n",
       "   0.004126,\n",
       "   0.004093,\n",
       "   0.00406,\n",
       "   0.004027,\n",
       "   0.003994,\n",
       "   0.003961,\n",
       "   0.003928,\n",
       "   0.003895,\n",
       "   0.003862,\n",
       "   0.003829,\n",
       "   0.003796,\n",
       "   0.003763,\n",
       "   0.00373,\n",
       "   0.003697,\n",
       "   0.003664,\n",
       "   0.003631,\n",
       "   0.003598,\n",
       "   0.003565,\n",
       "   0.003532,\n",
       "   0.003499,\n",
       "   0.003466,\n",
       "   0.003433,\n",
       "   0.0034,\n",
       "   0.003367,\n",
       "   0.003334,\n",
       "   0.003301,\n",
       "   0.003268,\n",
       "   0.003235,\n",
       "   0.003202,\n",
       "   0.003169,\n",
       "   0.003136,\n",
       "   0.003103,\n",
       "   0.00307,\n",
       "   0.003037,\n",
       "   0.003004,\n",
       "   0.002971,\n",
       "   0.002938,\n",
       "   0.002905,\n",
       "   0.002872,\n",
       "   0.002839,\n",
       "   0.002806,\n",
       "   0.002773,\n",
       "   0.00274,\n",
       "   0.002707,\n",
       "   0.002674,\n",
       "   0.002641,\n",
       "   0.002608,\n",
       "   0.002575,\n",
       "   0.002542,\n",
       "   0.002509,\n",
       "   0.002476,\n",
       "   0.002443,\n",
       "   0.00241,\n",
       "   0.002377,\n",
       "   0.002344,\n",
       "   0.002311,\n",
       "   0.002278,\n",
       "   0.002245,\n",
       "   0.002212,\n",
       "   0.002179]},\n",
       " 'date': '2023-12-25T21:02:00.473776',\n",
       " 'version': '8.0.203'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import ultralytics.nn.modules\n",
    "# 加载 PyTorch 模型\n",
    "model = torch.load(sys.path[0]+'\\\\'\"best.pt\")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
